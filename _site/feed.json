{
    "version": "https://jsonfeed.org/version/1",
    "title": "pboes",
    "home_page_url": "http://localhost:4000/",
    "feed_url": "http://localhost:4000/feed.json",
    "description": "personal website of Paul Boes",
    "icon": "http://localhost:4000/apple-touch-icon.png",
    "favicon": "http://localhost:4000/favicon.ico",
    "expired": false,
    
    "author":  {
        "name": "Paul Boes",
        "url": null,
        "avatar": null
    },
    
"items": [
    
        {
            "id": "http://localhost:4000/2021/09/20/confidence-intervals",
            "title": "Confidence intervals from hypothesis tests",
            "summary": null,
            "content_text": "Confidence intervals are a standard measure of confidence in data analysis: Almost any piece of software you use to run an OLS regression will provide you with a confidence interval - usually some range \\([a,b]\\subseteq \\mathbb{R}\\) for every estimated coefficient - as part of the summary of the regression. The question what this interval signifies is commonly answered by saying that, provided the assumptions of OLS regression hold, with high probability the true value of the quantity you estimate lies within the given interval.This answer confused me when I first heard it. Clearly an interval either contains a value or it doesn’t. So where does the probability come from? It turns out that the idea is simple (and quite independent of OLS regression) and that we can understand regression confidence intervals based on a simple but elegant connection between confidence intervals and hypothesis tests. But as is often the case, explanations online either lacked the kind of formal treatment that makes me actually understand something, or the math was too specifically focussed on OLS regression in order for me to understand how it depends on the latter’s many assumptions. So here I want to briefly present this connection in a self-contained way.1Let me first introduce some notation: We have a family of random variables \\(X_\\theta\\) that all take values in some measurable space \\(\\mathcal{X}\\) and whose probability distributions \\(P_\\theta\\) are parametrized by elements \\(\\theta\\) of another measurable space \\(\\Theta\\). In the context of a regression we can think of every \\(x \\in \\mathcal{X}\\) as data that I sampled, \\(X_\\theta\\) as the random variable describing the process of sampling, and \\(\\theta\\) as the (unknown) value of the coefficients in a linear model. We abstractly describe an estimator as a function \\(f: \\mathcal{X} \\to \\Theta\\) that maps any value of the random variable to some value \\(\\theta\\) (think mapping a sample to an estimate of the coefficients).A confidence interval then is a function that that maps values \\(x\\) into sets of parameter values such that, with sufficiently high probability contains \\(\\theta\\), if \\(x\\) was sampled from \\(P_\\theta\\). Lets formalize this. Given a confidence level \\(\\alpha \\in [0,1]\\), call a function \\(g: \\mathcal{X} \\to  \\mathcal{P}(\\Theta)\\) an \\(\\alpha\\)-confidence interval map if it has the property that, for any \\(\\theta \\in \\Theta\\),\\[\\mathrm{Prob}_{x \\sim P_\\theta}(\\theta \\in g(x)) \\geq \\alpha.\\]Here, \\(\\mathcal{P}(\\Theta)\\) denotes the power set (set of subsets) of \\(\\Theta\\). The most fruitful way to think about confidence intervals (at least for me) is then that there is a procedure (represented by \\(g\\)) for generating confidence intervals from samples, such that, if I follow this procedure, then regardless of the value of \\(\\theta\\), intervals generated according to this procedure will contain \\(\\theta\\) with probability \\(\\alpha\\).2But now that we have understood what confidence intervals are about, the natural question is how to construct them. Here, we can use a simple but nice connection to hypothesis tests: For a hypothesis test, I use a data sample and an estimator to decide whether I can reject a null hypothesis about the true value of an unknown parameter with some significance threshold. More precisely, a hypothesis test should accept a false null hypothesis with a probability at most  \\(\\alpha\\). Let’s again formalise this idea: For a significance threshold \\(\\alpha \\in [0,1]\\), call a function \\(h: \\Theta \\to \\mathcal{P}(\\Theta)\\) an \\(\\alpha\\)-hypothesis test for estimator \\(f\\) if, for any \\(\\theta\\), \\(\\mathrm{Prob}_{x \\sim P_\\theta}(f(x) \\in h(\\theta)) \\geq 1-\\alpha\\) and \\(\\theta \\in h(\\theta)\\). The way we turn this into a hypothesis test is via the procedure “If \\(f(x) \\notin h(\\theta)\\), reject the null hypothesis that \\(x\\) was sampled from \\(P_\\theta\\) with significance threshold \\(\\alpha\\).”Now, the nice thing is that we can construct an \\(1- \\alpha\\)-confidence interval map from any estimator \\(f\\) and \\(\\alpha\\)-hypothesis test for \\(f, h\\): Simply define\\[g(x) := \\{\\theta \\in\\Theta \\quad \\mathrm{ s.t. } \\quad f(x) \\in h(\\theta)\\}.\\]This maps any sample \\(x\\) to the set of parameter values \\(\\theta\\) for which the estimator \\(f(x)\\) survives the hypothesis test defined by \\(h\\) and the null hypothesis \\(\\theta\\). To see that this simple construction works note that, for any \\(\\theta\\),\\(\\mathrm{Prob}_{x \\sim P_\\theta}(\\theta \\in g(x)) = \\mathrm{Prob}_{x \\sim P_\\theta}(f(x) \\in h(\\theta)) \\geq 1- \\alpha\\),where we used that \\(\\theta \\in g(x) \\Leftrightarrow f(x) \\in h(\\theta)\\).To make all of this less abstract, let me translate the above into the common case of a simple linear regression model: Every \\(x\\) is a data sample consisting of \\(n\\) pairs \\((y_i, z_i)_{i=1}^n\\)such that, for each pair we assume that it was generated according to the model \\(Z_i = \\beta Y_i + \\beta_0 + \\epsilon_i\\), with additional assumptions about how the various errors terms are distributed, etc. If we want to use an \\(x\\) that we sample to generate a confidence interval (with confidence level \\(95\\%\\)) for the coefficient \\(\\beta\\), this means we are usually given the formula3\\[[\\hat{\\beta} - 1.96 \\times SE(\\hat{\\beta}), \\hat{\\beta} + 1.96 \\times SE(\\hat{\\beta})],\\]where \\(\\hat{\\beta} \\equiv \\hat{\\beta}(x)\\) is the OLS estimator of \\(\\beta\\) and \\(SE(\\hat{\\beta})\\) is its standard error. Using the above connection to hypothesis tests, we can identify this confidence interval map (since both OLS estimator is a function of the data, the above defines a map from data to sets of parameter values) as the one that is induced by an optimal4 \\(5\\%\\)-hypothesis test for the normalised OLS estimator : That is, we set \\(f(x) \\equiv \\hat{\\beta}(x)/SE(\\hat{\\beta}(x))\\)\\[h(\\theta) = \\arg \\min_{[a,b] \\subseteq \\mathbb{R}: \\mathrm{Prob}_{x \\sim P_\\theta}(\\frac{\\hat{\\beta}}{SE(\\hat{\\beta})} \\in [a,b] \\geq 0.95)} b - a,\\]which is a somewhat convoluted way to write that we define \\(h\\) as mapping any value \\(\\theta\\) to the smallest (in terms of the Lebesgue measure) interval such that, under the null hypothesis \\(\\theta\\),  the probability that the expression \\(\\hat{\\beta}/SE(\\hat{\\beta})\\) is contained in this interval is at least \\(95\\%\\). Now, it conveniently turns out that under the usual assumptions of simple linear regression models, we know the distribution of this expression analytically to be a Student’s t-distribution, which is a bell-shaped distribution, centered around \\(\\theta\\). Hence, $h$ defines a valid \\(95\\%\\)-hypothesis test for \\(\\hat{\\beta}\\)  and we can analytically evaluate its value (which is also called \\(t\\)-value) as\\(h(\\theta) = [\\theta - 1.96, \\theta + 1.96]\\).Finally, in order to evaluate \\(g\\) based on \\(h\\), let’s think about the set of values \\(\\theta\\) such that \\(f(x) \\in h(\\theta)\\). Since changing \\(\\theta\\) simply shifts \\(h(\\theta)\\) by a corresponding amount, we see that these are all the values within the interval \\([f(x) - 1.96, f(x)  + 1.96\\)]. But since this is now a confidence interval for the normalized OLS estimator, in order to get an interval for \\(\\hat{\\beta}\\), we multiply this interval by the standard error, resulting in exactly the confidence interval we were given above.            None of this is original, even the Wikipedia article on confidence intervals touches everything I say, but it also just states connections and doesn’t show them. &#8617;              An equivalent way of putting this is that the confidence interval is a random variable (namely, the one induced by \\(P_\\theta\\) and \\(g\\)). &#8617;              Changing the value of \\(\\alpha\\) only changes the factor in front of the standard error &#8617;              A hypothesis test is called optimal if it always maps every hypothesis to the smallest set of candidates that are to survive the test, where size is measured by the measure on the space. &#8617;      ",
            "content_html": "<p>Confidence intervals are a standard measure of confidence in data analysis: Almost any piece of software you use to run an OLS regression will provide you with a confidence interval - usually some range \\([a,b]\\subseteq \\mathbb{R}\\) for every estimated coefficient - as part of the summary of the regression. The question what this interval signifies is commonly answered by saying that, provided the assumptions of OLS regression hold, with high probability the true value of the quantity you estimate lies within the given interval.</p><p>This answer confused me when I first heard it. Clearly an interval either contains a value or it doesn’t. So where does the probability come from? It turns out that the idea is simple (and quite independent of OLS regression) and that we can understand regression confidence intervals based on a simple but elegant connection between confidence intervals and hypothesis tests. But as is often the case, explanations online either lacked the kind of formal treatment that makes me actually understand something, or the math was too specifically focussed on OLS regression in order for me to understand how it depends on the latter’s many assumptions. So here I want to briefly present this connection in a self-contained way.<sup id=\"fnref:nothing_new\" role=\"doc-noteref\"><a href=\"#fn:nothing_new\" class=\"footnote\" rel=\"footnote\">1</a></sup></p><p>Let me first introduce some notation: We have a family of random variables \\(X_\\theta\\) that all take values in some measurable space \\(\\mathcal{X}\\) and whose probability distributions \\(P_\\theta\\) are parametrized by elements \\(\\theta\\) of another measurable space \\(\\Theta\\). In the context of a regression we can think of every \\(x \\in \\mathcal{X}\\) as data that I sampled, \\(X_\\theta\\) as the random variable describing the process of sampling, and \\(\\theta\\) as the (unknown) value of the coefficients in a linear model. We abstractly describe an estimator as a function \\(f: \\mathcal{X} \\to \\Theta\\) that maps any value of the random variable to some value \\(\\theta\\) (think mapping a sample to an estimate of the coefficients).</p><p>A confidence interval then is a function that that maps values \\(x\\) into sets of parameter values such that, with sufficiently high probability contains \\(\\theta\\), if \\(x\\) was sampled from \\(P_\\theta\\). Lets formalize this. Given a confidence level \\(\\alpha \\in [0,1]\\), call a function \\(g: \\mathcal{X} \\to  \\mathcal{P}(\\Theta)\\) an <em>\\(\\alpha\\)-confidence interval map</em> if it has the property that, for any \\(\\theta \\in \\Theta\\),</p>\\[\\mathrm{Prob}_{x \\sim P_\\theta}(\\theta \\in g(x)) \\geq \\alpha.\\]<p>Here, \\(\\mathcal{P}(\\Theta)\\) denotes the power set (set of subsets) of \\(\\Theta\\). The most fruitful way to think about confidence intervals (at least for me) is then that there is a <em>procedure</em> (represented by \\(g\\)) for generating confidence intervals from samples, such that, if I follow this procedure, then regardless of the value of \\(\\theta\\), intervals generated according to this procedure will contain \\(\\theta\\) with probability \\(\\alpha\\).<sup id=\"fnref:confidence_interval\" role=\"doc-noteref\"><a href=\"#fn:confidence_interval\" class=\"footnote\" rel=\"footnote\">2</a></sup></p><p>But now that we have understood what confidence intervals are about, the natural question is how to construct them. Here, we can use a simple but nice connection to hypothesis tests: For a hypothesis test, I use a data sample and an estimator to decide whether I can reject a null hypothesis about the true value of an unknown parameter with some significance threshold. More precisely, a hypothesis test should accept a false null hypothesis with a probability at most  \\(\\alpha\\). Let’s again formalise this idea: For a significance threshold \\(\\alpha \\in [0,1]\\), call a function \\(h: \\Theta \\to \\mathcal{P}(\\Theta)\\) an <em>\\(\\alpha\\)-hypothesis test for estimator \\(f\\)</em> if, for any \\(\\theta\\), \\(\\mathrm{Prob}_{x \\sim P_\\theta}(f(x) \\in h(\\theta)) \\geq 1-\\alpha\\) and \\(\\theta \\in h(\\theta)\\). The way we turn this into a hypothesis test is via the procedure “If \\(f(x) \\notin h(\\theta)\\), reject the null hypothesis that \\(x\\) was sampled from \\(P_\\theta\\) with significance threshold \\(\\alpha\\).”</p><p>Now, the nice thing is that we can construct an \\(1- \\alpha\\)-confidence interval map from any estimator \\(f\\) and \\(\\alpha\\)-hypothesis test for \\(f, h\\): Simply define</p>\\[g(x) := \\{\\theta \\in\\Theta \\quad \\mathrm{ s.t. } \\quad f(x) \\in h(\\theta)\\}.\\]<p>This maps any sample \\(x\\) to the set of parameter values \\(\\theta\\) for which the estimator \\(f(x)\\) survives the hypothesis test defined by \\(h\\) and the null hypothesis \\(\\theta\\). To see that this simple construction works note that, for any \\(\\theta\\),</p><p>\\(\\mathrm{Prob}_{x \\sim P_\\theta}(\\theta \\in g(x)) = \\mathrm{Prob}_{x \\sim P_\\theta}(f(x) \\in h(\\theta)) \\geq 1- \\alpha\\),</p><p>where we used that \\(\\theta \\in g(x) \\Leftrightarrow f(x) \\in h(\\theta)\\).</p><p>To make all of this less abstract, let me translate the above into the common case of a simple linear regression model: Every \\(x\\) is a data sample consisting of \\(n\\) pairs \\((y_i, z_i)_{i=1}^n\\)such that, for each pair we assume that it was generated according to the model \\(Z_i = \\beta Y_i + \\beta_0 + \\epsilon_i\\), with additional assumptions about how the various errors terms are distributed, etc. If we want to use an \\(x\\) that we sample to generate a confidence interval (with confidence level \\(95\\%\\)) for the coefficient \\(\\beta\\), this means we are usually given the formula<sup id=\"fnref:change_alpha\" role=\"doc-noteref\"><a href=\"#fn:change_alpha\" class=\"footnote\" rel=\"footnote\">3</a></sup></p>\\[[\\hat{\\beta} - 1.96 \\times SE(\\hat{\\beta}), \\hat{\\beta} + 1.96 \\times SE(\\hat{\\beta})],\\]<p>where \\(\\hat{\\beta} \\equiv \\hat{\\beta}(x)\\) is the OLS estimator of \\(\\beta\\) and \\(SE(\\hat{\\beta})\\) is its standard error. Using the above connection to hypothesis tests, we can identify this confidence interval map (since both OLS estimator is a function of the data, the above defines a map from data to sets of parameter values) as the one that is induced by an optimal<sup id=\"fnref:why_optimal\" role=\"doc-noteref\"><a href=\"#fn:why_optimal\" class=\"footnote\" rel=\"footnote\">4</a></sup> \\(5\\%\\)-hypothesis test for the normalised OLS estimator : That is, we set \\(f(x) \\equiv \\hat{\\beta}(x)/SE(\\hat{\\beta}(x))\\)</p>\\[h(\\theta) = \\arg \\min_{[a,b] \\subseteq \\mathbb{R}: \\mathrm{Prob}_{x \\sim P_\\theta}(\\frac{\\hat{\\beta}}{SE(\\hat{\\beta})} \\in [a,b] \\geq 0.95)} b - a,\\]<p>which is a somewhat convoluted way to write that we define \\(h\\) as mapping any value \\(\\theta\\) to the smallest (in terms of the Lebesgue measure) interval such that, under the null hypothesis \\(\\theta\\),  the probability that the expression \\(\\hat{\\beta}/SE(\\hat{\\beta})\\) is contained in this interval is at least \\(95\\%\\). Now, it conveniently turns out that under the usual assumptions of simple linear regression models, we know the distribution of this expression analytically to be a Student’s t-distribution, which is a bell-shaped distribution, centered around \\(\\theta\\). Hence, $h$ defines a valid \\(95\\%\\)-hypothesis test for \\(\\hat{\\beta}\\)  and we can analytically evaluate its value (which is also called \\(t\\)-value) as</p><p>\\(h(\\theta) = [\\theta - 1.96, \\theta + 1.96]\\).</p><p>Finally, in order to evaluate \\(g\\) based on \\(h\\), let’s think about the set of values \\(\\theta\\) such that \\(f(x) \\in h(\\theta)\\). Since changing \\(\\theta\\) simply shifts \\(h(\\theta)\\) by a corresponding amount, we see that these are all the values within the interval \\([f(x) - 1.96, f(x)  + 1.96\\)]. But since this is now a confidence interval for the normalized OLS estimator, in order to get an interval for \\(\\hat{\\beta}\\), we multiply this interval by the standard error, resulting in exactly the confidence interval we were given above.</p><hr /><div class=\"footnotes\" role=\"doc-endnotes\">  <ol>    <li id=\"fn:nothing_new\" role=\"doc-endnote\">      <p>None of this is original, even the Wikipedia article on confidence intervals touches everything I say, but it also just states connections and doesn’t show them. <a href=\"#fnref:nothing_new\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:confidence_interval\" role=\"doc-endnote\">      <p>An equivalent way of putting this is that the confidence interval is a random variable (namely, the one induced by \\(P_\\theta\\) and \\(g\\)). <a href=\"#fnref:confidence_interval\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:change_alpha\" role=\"doc-endnote\">      <p>Changing the value of \\(\\alpha\\) only changes the factor in front of the standard error <a href=\"#fnref:change_alpha\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:why_optimal\" role=\"doc-endnote\">      <p>A hypothesis test is called optimal if it always maps every hypothesis to the smallest set of candidates that are to survive the test, where size is measured by the measure on the space. <a href=\"#fnref:why_optimal\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>  </ol></div>",
            "url": "http://localhost:4000/2021/09/20/confidence-intervals",
            
            
            
            
            
            "date_published": "2021-09-20T00:00:00+00:00",
            "date_modified": "2021-09-20T00:00:00+00:00",
            
                "author": "Paul Boes"
            
        },
    
        {
            "id": "http://localhost:4000/2018/07/12/bitcoing-mining-as-a-sacrifice-ritual",
            "title": "Bitcoin mining as a sacrifice ritual",
            "summary": null,
            "content_text": "Assuming that you have money in some bank account, how do you know that next time you want to withdraw any of it, the bank won’t pretend that you’ve never paid anything into the account? The answer, I suppose, is that the bank is forced by the laws of the state you live in to document all its incoming and outgoing transfers in a difficult-to-forge manner, that this state can ask them to report those documents upon request, that this state is allowed to fine the bank in case of fraud, that further this state has sufficient credible executive power to enforce the above rights and that, finally, the prospect of being fined appears worse to the bank than simply being honest.This property of a currency, that anybody who owns some amount of it can rely on this amount not suddenly vanishing from his or her possession, I call its persistence and the reasoning above is exactly how, I think, currencies minted by states establish their persistence: through credible political and executive power. Abstractly speaking, what was going above is that, in every state, there exists a big book and every monetary transaction, such as you paying something into your account, is noted in this book. This book, and this book alone, decides in situations of conflict about who owns what. The credible political power of a state then is a way of (a) ensuring that this book is always up-to-date (by being able to enforce proper reporting) and (b) correcting discrepancies between what the book says and what the actual situation is.I think it is clear that persistence is an important and necessary property of any functioning currency and the question for decentralised currencies is: How do they achieve persistence?  The above mechanism cannot work because it is the very point of such currencies that there does not, abstractly or otherwise, exist a single big book that defines the collective state of ownership at any given time. Instead, in such currencies, everybody is allowed to keep their own book and the tricky bit is to design a mechanism that keeps the advantages of this decentralisation while ensuring, among other things, the persistence of the currency. MiningThe way in which bitcoin, the best-known cryptocurrency, ensures persistence is through a mechanism called /mining/. In very simplified form, this works as follows: Let \\(B_t\\) be the complete history of bitcoin transactions up to time \\(t\\). Then there exists a number \\(H(B_t)\\) that depends on \\(B_t\\) and that has the following properties:Given \\(B_t\\), in order to find \\(H(B_t)\\) one needs to solve a puzzle that, on average, requires a long run time on the computer, hence consuming a lot of electricity.For two different histories \\(B_t\\) and \\(B_t'\\), it’s practically impossible to infer anything about \\(H(B_t')\\) from knowing \\(H(B_t)\\), even if these two histories are almost identical.The puzzle has no structure so that the best strategy for solving it is always to randomly guess numbers.The basic rule in Bitcoin then is “Don’t believe any information about some history \\(B_t\\) unless it’s accompanied by \\(H(B_t)\\)”. A moment of thought will reveal that this is indeed an (ingenious!) way to ensure persistence of a decentralised currency: If your bank wanted to pretend that you haven’t given them money, then they can, of course, change the history in their local book from \\(B_t\\) (the true history) to \\(B_t'\\) (the false history), but as soon as they want to spend the money they took from you, they would have to convince a third party that \\(B_t'\\) is true, but if that third party plays according to the rules then the bank will have to calculate \\(H(B_t')\\) which costs them a lot of electricity and hence if the expected cost of fraud is higher than the gain then there is no point in attempting it! So it is the hardness of the puzzle that generates the trust necessary for the currency’s persistence!But what, you may ask, happens if technology advances and computer processors become much faster? Or if electricity in a country becomes cheaper? Then fraud might turn from being economically unfeasible to being feasible! But here’s the twist: Bitcoin adjusts the difficulty of the puzzle to accommodate such changes. More precisely, the difficulty is adjusted in such a way that the average time required for all miners, the people that do the mining, to find  \\(H(B_t)\\) is about ten minutes. In other words, Bitcoin creates persistence by making sure that the process by which it is decided who owns what is always sufficiently expensive in an external resource to disincentivize fraud. Note, however, that \\(H(B_t)\\) needs to be calculated also for the “true” history, which is why Bitcoin consumes so much electricity even when nobody attempts to cheat.Sacrifice ritualsWhat is a sacrifice ritual, in a wider sense? I don’t know a good definition but also don’t think a clear-cut one exists. Yet, I submit that the following list of properties delineates sacrifice rituals from other activities rather well: A sacrifice ritual involves  an act of irreversibility, i.e. something gets destroyed or lost irretrievably,  some form of hurting those that sacrifice,  theatricality, i.e. it is usually done publicly or there is a form of proof of sacrifice,decadence.Here, by decadence, I mean something quite specific that I want to distinguish from the notion of excess: An act is decadent if the destruction of some resource is a constitutive part of this act. In contrast, an act is excessive if it could have been realised with fewer resources than it was. To illustrate the difference, I would say that driving a Porsche car is decadent but not excessive, while accidentally heating with an open window is excessive but not decadent. I make this distinction because I don’t think that a sacrifice ritual is always excessive.Mining as a sacrifice ritualI think that from my presentation of it, it is pretty clear that mining satisfies the first three of the above characteristics of a sacrifice ritual. The only question is whether it is actually decadent. Why would it not? Well, one might argue that for miners the question about whether to participate in mining has nothing decadent about it, but that instead it is driven by profitability calculations and that the energy consumption of the mining process is, for them, certainly not the purpose of doing the mining. And I would agree with that. But I think that the miners are not the relevant community here. Rather, it’s the people holding bitcoin. For them I think the situation is quite different: Since they rely on the persistence of the currency, and since this persistence relies on miners running their computers to run a problem that, by construction, has to be wasted on random guessing of numbers (instead of, say, trying to solve helpful problems), mining has as its explicit purpose the wasting of energy and, as such, is clearly decadent in my terminology.A moment of thought on this also clarifies another telling parallel between mining and sacrifice rituals: They serve, partially, the same purpose, namely that of creating trust and stabilising social structure in the community where the sacrifice is carried out, such as the village or family. By sacrificing stock, for example, farmers symbolically, and publicly, reconfirm their loyalty to the community, by sacrificing private goods to the public. For instance, Hubert and Mauss in their classic essay on sacrifice write “… the act of abnegation implicit in every sacrifice, by recalling frequently to the consciousness of the individual the presence of collective forces, in fact, sustains their ideal existence.” (p.97 in Understanding Religious Sacrifice, ed. Jeffrey Carter)So, what do we make of this curious little insight? For one, looking at Bitcoin in this way nicely highlights the not so surprising fact that even the most radical technological innovations often work by exactly the same basic mechanisms as the most ancient practices. Moreover, it also puts an emphasis on the important economic role of destructive or dissipative mechanisms. Indeed, Georges Bataille made such mechanisms the very foundation of his own theory of economics, arguing that “Bourgeois” economists such as Smith but also Marx had overlooked their relevance. Finally, understanding better the connection between mining and sacrifice rituals might allow us to find alternative and less resource-intensive ways of creating persistence for cryptocurrencies (and people, of course, look a lot for such alternatives). Specifically, we might look at other ways in which trust is created in societies and see whether any of them offer themselves for application in the context of cryptocurrencies.",
            "content_html": "<p>Assuming that you have money in some bank account, how do you know that next time you want to withdraw any of it, the bank won’t pretend that you’ve never paid anything into the account? The answer, I suppose, is that the bank is forced by the laws of the state you live in to document all its incoming and outgoing transfers in a difficult-to-forge manner, that this state can ask them to report those documents upon request, that this state is allowed to fine the bank in case of fraud, that further this state has sufficient credible executive power to enforce the above rights and that, finally, the prospect of being fined appears worse to the bank than simply being honest.This property of a currency, that anybody who owns some amount of it can rely on this amount not suddenly vanishing from his or her possession, I call its <em>persistence</em> and the reasoning above is exactly how, I think, currencies minted by states establish their persistence: through credible political and executive power. </p><p>Abstractly speaking, what was going above is that, in every state, there exists a big book and every monetary transaction, such as you paying something into your account, is noted in this book. This book, and this book alone, decides in situations of conflict about who owns what. The credible political power of a state then is a way of (a) ensuring that this book is always up-to-date (by being able to enforce proper reporting) and (b) correcting discrepancies between what the book says and what the actual situation is.</p><p>I think it is clear that persistence is an important and necessary property of any functioning currency and the question for decentralised currencies is: How do they achieve persistence?  The above mechanism cannot work because it is the very point of such currencies that there does not, abstractly or otherwise, exist a single big book that defines the collective state of ownership at any given time. Instead, in such currencies, everybody is allowed to keep their own book and the tricky bit is to design a mechanism that keeps the advantages of this decentralisation while ensuring, among other things, the persistence of the currency. </p><h3 id=\"mining\">Mining</h3><p>The way in which bitcoin, the best-known cryptocurrency, ensures persistence is through a mechanism called /mining/. In very simplified form, this works as follows: Let \\(B_t\\) be the complete history of bitcoin transactions up to time \\(t\\). Then there exists a number \\(H(B_t)\\) that depends on \\(B_t\\) and that has the following properties:</p><p>Given \\(B_t\\), in order to find \\(H(B_t)\\) one needs to solve a puzzle that, on average, requires a long run time on the computer, hence consuming a lot of electricity.For two different histories \\(B_t\\) and \\(B_t'\\), it’s practically impossible to infer anything about \\(H(B_t')\\) from knowing \\(H(B_t)\\), even if these two histories are almost identical.The puzzle has no structure so that the best strategy for solving it is always to randomly guess numbers.</p><p>The basic rule in Bitcoin then is “Don’t believe any information about some history \\(B_t\\) unless it’s accompanied by \\(H(B_t)\\)”. A moment of thought will reveal that this is indeed an (ingenious!) way to ensure persistence of a decentralised currency: If your bank wanted to pretend that you haven’t given them money, then they can, of course, change the history in their local book from \\(B_t\\) (the true history) to \\(B_t'\\) (the false history), but as soon as they want to spend the money they took from you, they would have to convince a third party that \\(B_t'\\) is true, but if that third party plays according to the rules then the bank will have to calculate \\(H(B_t')\\) which costs them a lot of electricity and hence if the expected cost of fraud is higher than the gain then there is no point in attempting it! <em>So it is the hardness of the puzzle that generates the trust necessary for the currency’s persistence!</em></p><p>But what, you may ask, happens if technology advances and computer processors become much faster? Or if electricity in a country becomes cheaper? Then fraud might turn from being economically unfeasible to being feasible! But here’s the twist: <em>Bitcoin adjusts the difficulty of the puzzle to accommodate such changes.</em> More precisely, the difficulty is adjusted in such a way that the average time required for all miners, the people that do the mining, to find  \\(H(B_t)\\) is about ten minutes. In other words, Bitcoin creates persistence by making sure that the process by which it is decided who owns what is always sufficiently expensive in an external resource to disincentivize fraud. Note, however, that \\(H(B_t)\\) needs to be calculated also for the “true” history, which is why Bitcoin consumes so much electricity even when nobody attempts to cheat.</p><h3 id=\"sacrifice-rituals\">Sacrifice rituals</h3><p>What is a sacrifice ritual, in a wider sense? I don’t know a good definition but also don’t think a clear-cut one exists. Yet, I submit that the following list of properties delineates sacrifice rituals from other activities rather well: A sacrifice ritual involves</p><ul>  <li>an act of irreversibility, i.e. something gets destroyed or lost irretrievably,</li>  <li>some form of hurting those that sacrifice,</li>  <li>theatricality, i.e. it is usually done publicly or there is a form of proof of sacrifice,decadence.</li></ul><p>Here, by <em>decadence</em>, I mean something quite specific that I want to distinguish from the notion of excess: An act is decadent if the destruction of some resource is a constitutive part of this act. In contrast, an act is excessive if it could have been realised with fewer resources than it was. To illustrate the difference, I would say that driving a Porsche car is decadent but not excessive, while accidentally heating with an open window is excessive but not decadent. I make this distinction because I don’t think that a sacrifice ritual is always excessive.</p><h3 id=\"mining-as-a-sacrifice-ritual\">Mining as a sacrifice ritual</h3><p>I think that from my presentation of it, it is pretty clear that mining satisfies the first three of the above characteristics of a sacrifice ritual. The only question is whether it is actually decadent. Why would it not? Well, one might argue that for miners the question about whether to participate in mining has nothing decadent about it, but that instead it is driven by profitability calculations and that the energy consumption of the mining process is, for them, certainly not the purpose of doing the mining. And I would agree with that. But I think that the miners are not the relevant community here. Rather, it’s the people holding bitcoin. For <em>them</em> I think the situation is quite different: Since they rely on the persistence of the currency, and since this persistence relies on miners running their computers to run a problem that, by construction, has to be wasted on random guessing of numbers (instead of, say, trying to solve helpful problems), mining has as its explicit purpose the wasting of energy and, as such, is clearly decadent in my terminology.</p><p>A moment of thought on this also clarifies another telling parallel between mining and sacrifice rituals: They serve, partially, the same purpose, namely that of creating trust and stabilising social structure in the community where the sacrifice is carried out, such as the village or family. By sacrificing stock, for example, farmers symbolically, and publicly, reconfirm their loyalty to the community, by sacrificing private goods to the public. For instance, Hubert and Mauss in their classic essay on sacrifice write “… the act of abnegation implicit in every sacrifice, by recalling frequently to the consciousness of the individual the presence of collective forces, in fact, sustains their ideal existence.” (p.97 in <em>Understanding Religious Sacrifice</em>, ed. Jeffrey Carter)</p><p>So, what do we make of this curious little insight? For one, looking at Bitcoin in this way nicely highlights the not so surprising fact that even the most radical technological innovations often work by exactly the same basic mechanisms as the most ancient practices. Moreover, it also puts an emphasis on the important <em>economic</em> role of destructive or dissipative mechanisms. Indeed, Georges Bataille made such mechanisms the very foundation of his own theory of economics, arguing that “Bourgeois” economists such as Smith but also Marx had overlooked their relevance. Finally, understanding better the connection between mining and sacrifice rituals might allow us to find alternative and less resource-intensive ways of creating persistence for cryptocurrencies (and people, of course, look a lot for such alternatives). Specifically, we might look at other ways in which trust is created in societies and see whether any of them offer themselves for application in the context of cryptocurrencies.</p>",
            "url": "http://localhost:4000/2018/07/12/bitcoing-mining-as-a-sacrifice-ritual",
            
            
            
            
            
            "date_published": "2018-07-12T00:00:00+00:00",
            "date_modified": "2018-07-12T00:00:00+00:00",
            
                "author": "Paul Boes"
            
        },
    
        {
            "id": "http://localhost:4000/2016/07/31/stacking-superstition",
            "title": "Stacking Superstition",
            "summary": null,
            "content_text": "Stacking SuperstitionIn every society there exist a lot of rituals that form a big part of what would be called the “culture” of this society. Some of those involve body actions, while others don’t. Examples of the former are holding open a door for someone or clapping your hands to applaud somebody, raising your fist to signal intense joy or anger. Examples of the latter are the “hi,hi,how are you,good”-exchange at the beginning of conversations and other speaking protocols. Even though there is no tight boundary between these two kinds of ritual, I think we are certainly in the regime of the first whenever in messages we’re using things like clap, facepalm, and other memes imitating a physical action. Now, there are special cases of the first kind, rituals involving some form of magic - acts of superstition such as “knocking on wood” or gonging a gong as part of a prayer. Translating these rituals into messages involving bits like gong or #knockonwood seems question-begging both to me and everybody that I talked to about this. Why is that? What underlies this difficulty of translating “magical rituals” into the digital realm?I don’t consider myself superstitious but I am interested in this question, because I believe that the answer to the above questions has to do with the physicality of physical space and a consequent materiality of objects that are involved in magical rituals. This text sketches out my reasons for this belief and muses about its implications for any kind of “culture of digital space”.1 The real occasion for writing this text, however, is the “knockblock” I recently built and that - I hope - evokes everything I talk about here in an instant.The knockblock consists of a transparent box in the middle of which sits a little block of wood that can be hit by a solenoid-hammer underneath it. This solenoid-hammer is connected to the web and triggered whenever people on Twitter write about things that would usually trigger a “knock-on-wood” ritual.⁠2 I hope that you will keep the box, which I’ll just call ‘knock-block’ for lack of a worse rhyme, in the back of your mind while reading this.So, why do I think that magical rituals are difficult to translate into digital space because of the “physicality of physical space and a consequent materiality of objects” that they involve?⁠3 Let me first clarify the notions here. By “physicality of physical space” I mean this: That because of there being laws of physics, what we can do in physical space is not unlimited.⁠4 You cannot fall upwards (for the Ozzies and the ISS crowd, against the gravitational potential). You cannot walk through a rock. By materiality, I roughly mean that property of the stuff in our world that allows us to treat parts of it as objects - distinct, independent. Materiality is much more of a cultural notion than physicality. What people consider to be an object, when, for example, the clay turns statue, depends, I think, mostly on how clay and statues figure in the cultural eco-system of these people. An important aspect of materiality for anthropologists it seems, albeit the term there is used with a slightly different meaning, is that as a quality it transcends the human arena. For instance, Daniel Miller and Heather Horst, in their introduction to the recently edited volume “Digital Anthropology”, argue that the following Principle of Materiality has to become one of the founding columns of any form of Digital Anthropology:  “It is impossible to become human other than through socializing within a material world of cultural artefacts that include the order, agency and relationships between things themselves and not just their relationship to persons. Artefacts do far more than just express human intention”5This transcendence, as it is expressed in the last sentence of the quote, is, I think, rooted in physicality: Objects can develop their ontological independence from humans because they are situated in a world over which we only have limited power.⁠6And materiality is necessary for magic, I think, for the following reason: Magic, almost by definition, involves higher powers, beyond human. Having these powers enter our lives as mediated through objects (which, if we buy the Principle of Materiality, is necessary), requires objects to be somehow independent of humans. If we would not be able to treat material objects as in some sense ontologically independent of humans, then we could not, I think, assign any magical qualities to them in a credible fashion (credible to ourselves). Indeed, we need objects to possess just that quality which is expressed in the Principle of Materiality. And since, as I suggest, material objects in physical space gain this special ontic independence through their physicality, physicality would hence enable magical rituals.⁠7 Finally, since by definition digital objects cannot be physical in the above sense, they cannot, the argument concludes, credibly be endowed with magical capabilities.But this is obviously not the end of the story. Because nothing of the above implies that there cannot be a materiality of digital space, and really it was the material rather than the physical that I took to be responsible for the possibility of being endowed with magical capability. In fact, the above authors suggest the Principle of Materiality to emphasise that Digital Anthropology can employ exactly the same methods as any other Anthropology, that there is no methodological or disciplinary discontinuity, because there is no discontinuity in the subject matter: The digital world is just as mediated as any other. But this is where things get interesting. Because we’re now asking what could substitute the physicality of physical space in digital spaces and give rise to materiality of the stuff that populates the latter .Basically, I see three possible paths to credible magic in the “digital era” or however you want to call it. In order of increasing likelihood in my opinion: 1. We find that physicality is not only sufficient for materialities capable of magic, but also necessary. This may for example be because we think that physical space is special and singled out among all spaces, because it is the space in which our bodies live, and that no other space can have that special zzzing to it. 2. Any form of physicality of digital space that allows for magic has to mimic the physicality of physical space. So those objects in digital space that end up possessing magical powers would act like physical objects - they resist, they don’t apologise when you walk against them, etc. 3. There are many ways in which digital space can develop a materiality suitable for magic and how they do so is not necessarily connected to the contingent physical realm with its contingent physical laws at all. Let me go through these three in turn:      I don’t think so. In fact, another reason for placing my knock-block in a plexiglass shell was to provoke a sense of the following: Imagine in the future people rent little “guardian angel”-modules, just like my knock-block. These will be on the grid 24/7, just like now your cloud space. They will follow each of your steps in the web and knock/gong/clap whenever suitable, to make sure digital existence has a proper physical accompaniment, and your Karma never has to suffer again. Where this box sits doesn’t matter, just like it doesn’t matter where Facebook has its server farms. I envision massive storage halls with millions of knocks and gongs (and me as the housekeeper #dreamjob). I think this is a bizarre vision and I think people have more fantasy for magic in digital times than to make it true.        So let’s assume that some form of physicality of digital space is possible. Looking back at physicality of physical space, I think that from an operational point of view - that is, whenever we are physically interacting with stuff in order to modify it or use it as an instrument - physicality shows up in a kind of resistance: The hammer is heavy, the stone stubborn and certainly not carrying itself away, the rope gets stuck in every possible corner. I think that it is in this hands-on fashion that we develop our sense of physicality and along which any substitute is to be found. Claim: Digital objects will have to be non-conforming, our operational access to them limited, in order for us to consider them ontologically sufficiently autonomous to act as carriers of magical momentum. As a first thought experiment, you could think of Tetris, but now the blocks don’t fall swiftly and gently (ok, they never did), but instead you have to pull them down the screen, with friction and all that. Surely this wouldn’t be that much of a fun game, but immediately each of those blocks feels much more like a rock to me. The second possible answer to the above question, then, would be that physicality of digital space is limited to mimicking objects in physical space, just like in the case of Tetris. I don’t see a good reason for this to be case.    To me the situation is a little bit like urban spaces and nature. People like to be nostalgic about nature and the wild, but to me this often involves a neglect of the materiality and magic of urban spaces. I feel that it is very clear that people have already learned to develop notions of materiality, probably do so all the time. And I really don’t see how “nature” and “urban space” are any closer or farther from another than “physical space” and “digital space”.        The laws of digital spaces are, a priori, completely independent of those of physical space.⁠8 You can create any (Turing computable) world with them and the only limit is our imagination (which really brings the number back into this solar system…). The conditions of materiality, i.e. the notion of “resistance” or anything that, if my way of thinking about this make sense, would make it behave in such a way that I think of it as an ontological entity different from myself, are not limited to gravitational fields and object persistence. I think that  Bourdieu’s concept of habitus could be interesting here, because it would be through my interacting with digital objects on a frequent basis that I come to accept these objects as being different from me, independent of me. And this would be just what makes them material. But this is pretty much where I got to in my thinking about this.  I feel that there is a big societal demand for cultural narratives that provide a materiality of digital space. And I feel confirmed about this every time I enter a gallery and what seems to be contemporary mainstream theory of art:9 During my research for this post, I always again come across this “speculative realism” movement and the notion of an object-oriented ontology. The one tenet of theirs that is relevant for me here is that they reject post-Kantian philosophies, basically anything that is based on the latter’s Kopernican turn, making the sensual world the object of human cognition, rather than the other way around. Instead, in an object-oriented ontology, all objects share the same ontological plane with humans, and none of us (that is, objects and humans) is special. Obviously, this is very much related to this text and I think this movement, or conglomerate of people (and objects), draws a lot of inspiration from the social sciences, anthropology/STS in particular. Now, even though I personally still cling on to my Kantian convictions, if we don’t ask for the feasibility of a philosophical current but instead ask why different currents are trendy at different times, I feel that it is very obvious why speculative realism should gain so much attention: The time is ripe for it. Object-oriented ontologies are one natural way to approach the question of of materiality in digital spaces and so the feedback for speculative realism again feeds my conviction that we’re in the process of formulating such narratives. And given the propensity of people to stick with the first solution that doesn’t blow up in their faces immediately, which narrative we end up with will probably be both a) very contingent on the political development/path of discourse and b) tremendously important (you know, for our children and stuff).I’d be really happy if anybody reading this would share his/her thoughts with me, because I will certainly continue to think about it. While my knock-block gently knocks….            Of course, talking about digital space and physical space as if they’re two separate spaces goes very much against the spirit of what I write about. But I think that still everybody kind of knows what I mean here (what’s in your browser belongs to digital, the cup sitting left of your computer to physical space) and this very fact (that people will know what I mean) I take to sufficiently justify my use of it, since I am, at the end of the day, concerned with how this boundary will develop. &#8617;              In practice, both because it is impossible to filter all Twitter posts for such instances and because I want the box to only hammer at the time order of seconds, I actually filter for only a subset of these ritual-triggering instances which I arbitrarily selected, something for which I don’t think I require theoretical justification. &#8617;              Also, don’t get me wrong. There are also all kinds of more spiritual considerations when thinking about magic. You may think that the person’s focus or energy is more important than any physical event, or that it has to be the person itself knocking something, that this cannot be outsourced to knock-blocks to begin with. These points are valid but I’m thinking about magic only as a means to another end, namely that of discussing physicality, so I only consider this latter point, which I think will have to be important in any discussion of magic anyway. &#8617;              It doesn’t really matter to me whether you think of this as a property of physical space or sitting in people’s heads - pick your favourite. &#8617;              Digital Anthropology; Heather Horst and Daniel Miller (eds.); London: Berg Publishers; 2012 &#8617;              This is one reason why I placed the block of wood into a plexiglass shell: For this sense of ontic independence. The block of wood is in there, you may know the whole Divine Comedy by heart but that doesn’t allow you to reach through the box to touch it! NB: It’s very much the point of all this that, in order to manifest this intention of mine, I use an actual material again. NBB: It’s the bloody non-irony of this latter fact that gets my heart pumping! &#8617;              In fact, taking this thought of the fundamental importance of physicality for material and magical cultures as a starting point, we could interpret magical rituals as exactly those rituals in which physicality itself is “celebrated” or in which a kind of contract between people and their physical environment is renewed…By knocking on wood, by gonging a gong, I produce a kind of “space-time event” that reconfirms the physical in the world around me, I double-check and celebrate that my knocking is still me by the resistance of the wood, that allows me to think of the physical world around me as, potentially, a manifold of gongings (where here I importantly mean the event, not the act) and so forth. But this thought would take us off-topic and is not necessary for the following. &#8617;              I find it in general quite surprising how little people have deviated from recreating spaces that follow the same laws as the laws of the observable physical world. &#8617;              And surely contemporary art is always a pretty good mirror of which kind of Wiener Schnitzel society is currently nagging on, no? - I guess if psychoanalytically inclined one could say that art is where societies dream maybe… &#8617;      ",
            "content_html": "<h1 id=\"stacking-superstition\">Stacking Superstition</h1><p>In every society there exist a lot of rituals that form a big part of what would be called the “culture” of this society. Some of those involve body actions, while others don’t. Examples of the former are holding open a door for someone or clapping your hands to applaud somebody, raising your fist to signal intense joy or anger. Examples of the latter are the “hi,hi,how are you,good”-exchange at the beginning of conversations and other speaking protocols. Even though there is no tight boundary between these two kinds of ritual, I think we are certainly in the regime of the first whenever in messages we’re using things like <em>clap</em>, <em>facepalm</em>, and other memes imitating a physical action. Now, there are special cases of the first kind, rituals involving some form of magic - acts of superstition such as “knocking on wood” or gonging a gong as part of a prayer. Translating these rituals into messages involving bits like <em>gong</em> or #knockonwood seems question-begging both to me and everybody that I talked to about this. Why is that? What underlies this difficulty of translating “magical rituals” into the digital realm?</p><p>I don’t consider myself superstitious but I am interested in this question, because I believe that the answer to the above questions has to do with the <em>physicality</em> of physical space and a consequent <em>materiality</em> of objects that are involved in magical rituals. This text sketches out my reasons for this belief and muses about its implications for any kind of “culture of digital space”.<sup id=\"fnref:1\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup> The real occasion for writing this text, however, is the “<a href=\"https://beingbutlumps.wordpress.com/portfolio/knockblock/\">knockblock</a>” I recently built and that - I hope - evokes everything I talk about here in an instant.</p><p>The knockblock consists of a transparent box in the middle of which sits a little block of wood that can be hit by a solenoid-hammer underneath it. This solenoid-hammer is connected to the web and triggered whenever people on Twitter write about things that would usually trigger a “knock-on-wood” ritual.⁠<sup id=\"fnref:2\" role=\"doc-noteref\"><a href=\"#fn:2\" class=\"footnote\" rel=\"footnote\">2</a></sup> I hope that you will keep the box, which I’ll just call ‘knock-block’ for lack of a worse rhyme, in the back of your mind while reading this.</p><p><img src=\"https://beingbutlumps.files.wordpress.com/2016/07/box2.jpg\" alt=\"Box2\" /></p><iframe width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/Bv33IueR1ZQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe><p>So, why do I think that magical rituals are difficult to translate into digital space because of the “<em>physicality</em> of physical space and a consequent <em>materiality</em> of objects” that they involve?⁠<sup id=\"fnref:3\" role=\"doc-noteref\"><a href=\"#fn:3\" class=\"footnote\" rel=\"footnote\">3</a></sup> Let me first clarify the notions here. By “physicality of physical space” I mean this: That because of there being laws of physics, what we can do in physical space is not unlimited.⁠<sup id=\"fnref:4\" role=\"doc-noteref\"><a href=\"#fn:4\" class=\"footnote\" rel=\"footnote\">4</a></sup> You cannot fall upwards (for the Ozzies and the ISS crowd, against the gravitational potential). You cannot walk through a rock. By materiality, I roughly mean that property of the stuff in our world that allows us to treat parts of it as objects - distinct, independent. Materiality is much more of a cultural notion than physicality. What people consider to be an object, when, for example, the clay turns statue, depends, I think, mostly on how clay and statues figure in the cultural eco-system of these people. An important aspect of materiality for anthropologists it seems, albeit the term there is used with a slightly different meaning, is that as a quality it transcends the human arena. For instance, Daniel Miller and Heather Horst, in their introduction to the recently edited volume “Digital Anthropology”, argue that the following <em>Principle of Materiality</em> has to become one of the founding columns of any form of Digital Anthropology:</p><blockquote>  <p>“It is impossible to become human other than through socializing within a material world of cultural artefacts that include the order, agency and relationships between things themselves and not just their relationship to persons. Artefacts do far more than just express human intention”<sup id=\"fnref:5\" role=\"doc-noteref\"><a href=\"#fn:5\" class=\"footnote\" rel=\"footnote\">5</a></sup></p></blockquote><p>This transcendence, as it is expressed in the last sentence of the quote, is, I think, rooted in physicality: Objects can develop their ontological independence from humans because they are situated in a world over which we only have limited power.⁠<sup id=\"fnref:6\" role=\"doc-noteref\"><a href=\"#fn:6\" class=\"footnote\" rel=\"footnote\">6</a></sup></p><p>And materiality is necessary for magic, I think, for the following reason: Magic, almost by definition, involves higher powers, beyond human. Having these powers enter our lives as mediated through objects (which, if we buy the Principle of Materiality, is necessary), requires objects to be somehow independent of humans. If we would not be able to treat material objects as in some sense ontologically independent of humans, then we could not, I think, assign any magical qualities to them in a credible fashion (credible to ourselves). Indeed, we need objects to possess just that quality which is expressed in the Principle of Materiality. And since, as I suggest, material objects in physical space gain this special ontic independence through their physicality, physicality would hence enable magical rituals.⁠<sup id=\"fnref:7\" role=\"doc-noteref\"><a href=\"#fn:7\" class=\"footnote\" rel=\"footnote\">7</a></sup> Finally, since by definition digital objects cannot be physical in the above sense, they cannot, the argument concludes, credibly be endowed with magical capabilities.</p><p>But this is obviously not the end of the story. Because nothing of the above implies that there cannot be a <em>materiality</em> of digital space, and really it was the material rather than the physical that I took to be responsible for the possibility of being endowed with magical capability. In fact, the above authors suggest the Principle of Materiality to emphasise that Digital Anthropology can employ exactly the same methods as any other Anthropology, that there is no methodological or disciplinary discontinuity, because there is no discontinuity in the subject matter: The digital world is just as <em>mediated</em> as any other. But this is where things get interesting. Because we’re now asking what could substitute the physicality of physical space in digital spaces and give rise to materiality of the stuff that populates the latter .</p><p>Basically, I see three possible paths to credible magic in the “digital era” or however you want to call it. In order of increasing likelihood in my opinion: 1. We find that physicality is not only sufficient for materialities capable of magic, but also necessary. This may for example be because we think that physical space is special and singled out among all spaces, because it is the space in which our bodies live, and that no other space can have that special zzzing to it. 2. Any form of physicality of digital space that allows for magic has to <em>mimic</em> the physicality of physical space. So those objects in digital space that end up possessing magical powers would act like physical objects - they resist, they don’t apologise when you walk against them, etc. 3. There are many ways in which digital space can develop a materiality suitable for magic and how they do so is not necessarily connected to the contingent physical realm with its contingent physical laws at all. Let me go through these three in turn:</p><ol>  <li>    <p>I don’t think so. In fact, another reason for placing my knock-block in a plexiglass shell was to provoke a sense of the following: Imagine in the future people rent little “guardian angel”-modules, just like my knock-block. These will be on the grid 24/7, just like now your cloud space. They will follow each of your steps in the web and knock/gong/clap whenever suitable, to make sure digital existence has a proper physical accompaniment, and your Karma never has to suffer again. Where this box sits doesn’t matter, just like it doesn’t matter where Facebook has its server farms. I envision massive storage halls with millions of knocks and gongs (and me as the housekeeper #dreamjob). I think this is a bizarre vision and I think people have more fantasy for magic in digital times than to make it true.</p>  </li>  <li>    <p>So let’s assume that some form of physicality of digital space is possible. Looking back at physicality of physical space, I think that from an operational point of view - that is, whenever we are physically interacting with stuff in order to modify it or use it as an instrument - physicality shows up in a kind of resistance: The hammer is heavy, the stone stubborn and certainly not carrying itself away, the rope gets stuck in every possible corner. I think that it is in this hands-on fashion that we develop our sense of physicality and along which any substitute is to be found. Claim: Digital objects will have to be non-conforming, our operational access to them limited, in order for us to consider them ontologically sufficiently autonomous to act as carriers of magical momentum. As a first thought experiment, you could think of Tetris, but now the blocks don’t fall swiftly and gently (ok, they never did), but instead you have to pull them down the screen, with friction and all that. Surely this wouldn’t be that much of a fun game, but immediately each of those blocks feels much more like a rock to me. The second possible answer to the above question, then, would be that physicality of digital space is limited to mimicking objects in physical space, just like in the case of Tetris. I don’t see a good reason for this to be case.</p>    <p>To me the situation is a little bit like urban spaces and nature. People like to be nostalgic about nature and the wild, but to me this often involves a neglect of the materiality and magic of urban spaces. I feel that it is very clear that people have already learned to develop notions of materiality, probably do so all the time. And I really don’t see how “nature” and “urban space” are any closer or farther from another than “physical space” and “digital space”.</p>  </li>  <li>    <p>The laws of digital spaces are, a priori, completely independent of those of physical space.⁠<sup id=\"fnref:8\" role=\"doc-noteref\"><a href=\"#fn:8\" class=\"footnote\" rel=\"footnote\">8</a></sup> You can create any (Turing computable) world with them and the only limit is our imagination (which really brings the number back into this solar system…). The conditions of materiality, i.e. the notion of “resistance” or anything that, if my way of thinking about this make sense, would make it behave in such a way that I think of it as an ontological entity different from myself, are not limited to gravitational fields and object persistence. I think that  Bourdieu’s concept of <em>habitus</em> could be interesting here, because it would be through my interacting with digital objects on a frequent basis that I come to accept these objects as being different from me, independent of me. And this would be just what makes them material. But this is pretty much where I got to in my thinking about this.</p>  </li></ol><p>I feel that there is a big societal demand for cultural narratives that provide a materiality of digital space. And I feel confirmed about this every time I enter a gallery and what seems to be contemporary mainstream theory of art:<sup id=\"fnref:9\" role=\"doc-noteref\"><a href=\"#fn:9\" class=\"footnote\" rel=\"footnote\">9</a></sup> During my research for this post, I always again come across this “speculative realism” movement and the notion of an object-oriented ontology. The one tenet of theirs that is relevant for me here is that they reject post-Kantian philosophies, basically anything that is based on the latter’s Kopernican turn, making the sensual world the object of human cognition, rather than the other way around. Instead, in an object-oriented ontology, all objects share the same ontological plane with humans, and none of us (that is, objects and humans) is special. Obviously, this is very much related to this text and I think this movement, or conglomerate of people (and objects), draws a lot of inspiration from the social sciences, anthropology/STS in particular. Now, even though I personally still cling on to my Kantian convictions, if we don’t ask for the feasibility of a philosophical current but instead ask why different currents are trendy at different times, I feel that it is very obvious why speculative realism should gain so much attention: The time is ripe for it. Object-oriented ontologies are one natural way to approach the question of of materiality in digital spaces and so the feedback for speculative realism again feeds my conviction that we’re in the process of formulating such narratives. And given the propensity of people to stick with the first solution that doesn’t blow up in their faces immediately, which narrative we end up with will probably be both a) very contingent on the political development/path of discourse and b) tremendously important (you know, for our children and stuff).</p><p>I’d be really happy if anybody reading this would share his/her thoughts with me, because I will certainly continue to think about it. While my knock-block gently knocks….</p><hr /><div class=\"footnotes\" role=\"doc-endnotes\">  <ol>    <li id=\"fn:1\" role=\"doc-endnote\">      <p>Of course, talking about digital space and physical space as if they’re two separate spaces goes very much against the spirit of what I write about. But I think that still everybody kind of knows what I mean here (what’s in your browser belongs to digital, the cup sitting left of your computer to physical space) and this very fact (that people will know what I mean) I take to sufficiently justify my use of it, since I am, at the end of the day, concerned with how this boundary will develop. <a href=\"#fnref:1\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:2\" role=\"doc-endnote\">      <p>In practice, both because it is impossible to filter all Twitter posts for such instances and because I want the box to only hammer at the time order of seconds, I actually filter for only a subset of these ritual-triggering instances which I arbitrarily selected, something for which I don’t think I require theoretical justification. <a href=\"#fnref:2\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:3\" role=\"doc-endnote\">      <p>Also, don’t get me wrong. There are also all kinds of more spiritual considerations when thinking about magic. You may think that the person’s focus or energy is more important than any physical event, or that it has to be the person itself knocking something, that this cannot be outsourced to knock-blocks to begin with. These points are valid but I’m thinking about magic only as a means to another end, namely that of discussing physicality, so I only consider this latter point, which I think will have to be important in any discussion of magic anyway. <a href=\"#fnref:3\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:4\" role=\"doc-endnote\">      <p>It doesn’t really matter to me whether you think of this as a property of physical space or sitting in people’s heads - pick your favourite. <a href=\"#fnref:4\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:5\" role=\"doc-endnote\">      <p><em>Digital Anthropology;</em> Heather Horst and Daniel Miller (eds.); London: Berg Publishers; 2012 <a href=\"#fnref:5\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:6\" role=\"doc-endnote\">      <p>This is one reason why I placed the block of wood into a plexiglass shell: For this sense of ontic independence. The block of wood is in there, you may know the whole Divine Comedy by heart but that doesn’t allow you to reach through the box to touch it! NB: It’s very much the point of all this that, in order to manifest this intention of mine, I use an actual material again. NBB: It’s the bloody non-irony of this latter fact that gets my heart pumping! <a href=\"#fnref:6\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:7\" role=\"doc-endnote\">      <p>In fact, taking this thought of the fundamental importance of physicality for material and magical cultures as a starting point, we could interpret magical rituals as exactly those rituals in which physicality itself is “celebrated” or in which a kind of contract between people and their physical environment is renewed…By knocking on wood, by gonging a gong, I produce a kind of “space-time event” that reconfirms the physical in the world around me, I double-check and celebrate that my knocking is still me by the resistance of the wood, that allows me to think of the physical world around me as, potentially, a manifold of gongings (where here I importantly mean the event, not the act) and so forth. But this thought would take us off-topic and is not necessary for the following. <a href=\"#fnref:7\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:8\" role=\"doc-endnote\">      <p>I find it in general quite surprising how little people have deviated from recreating spaces that follow the same laws as the laws of the observable physical world. <a href=\"#fnref:8\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>    <li id=\"fn:9\" role=\"doc-endnote\">      <p>And surely contemporary art is always a pretty good mirror of which kind of Wiener Schnitzel society is currently nagging on, no? - I guess if psychoanalytically inclined one could say that art is where societies dream maybe… <a href=\"#fnref:9\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>    </li>  </ol></div>",
            "url": "http://localhost:4000/2016/07/31/stacking-superstition",
            
            
            
            
            
            "date_published": "2016-07-31T00:00:00+00:00",
            "date_modified": "2016-07-31T00:00:00+00:00",
            
                "author": "Paul Boes"
            
        },
    
        {
            "id": "http://localhost:4000/2016/04/28/280/",
            "title": "Why can we produce paradoxes of self-reference?",
            "summary": null,
            "content_text": "It's been a while. The reasons are the usual so let me not do go into lengthy explanations and apologies. I won't pursue the megalomanic project that I started the blog for, at least not for now. An essay on something related that I wrote on Kant's Mathematical Antinomies in Oxford, and a couple of conversations with clever people, showed me that my basic position concerning these things is even more problematic than I had foreseen (again, the usual...), so I'll pause that one to think a bit longer. For now, I have some other, more miscellaneous stuff lined up, and I'll start with a little quirky idea, nothing with much force, but, I find, interesting.Let me put on my Cartesian ruff and do some armchair musing about the physiology of abstraction, that is, lets look at whether we can go say anything, by way of introspection, about what happens in the brain when we abstract (I know, it's 2016, I'm neither a philosopher of mind, nor a neuroscientist, this is just ridiculous...but then, from the little researching I did, there seems to exist no scientific theory on this at the moment and also it's a gloomy Sunday, so take it more as a form of hang over brain jogging...).Concretely, I want to think about the following: Start by noting that there are such things as paradoxes of self-reference, which means that people have an ability to formulate paradoxes of self-reference. The formulation of such paradoxes usually involves some form of abstraction (more below). This means that, if introspective observations of this kind have any relevance at all for the formulation of physiological models of abstraction (which I think, in principle they do, although I'm happy to admit that there are a zillion more pressing things to consider for the latter), then any such model would have to explain this ability of ours, ideally somewhat elegantly. Can we, then, playing the good ol' \"inference-to-the-best-explanation\"-game, develop a simple model of abstraction that naturally gives rise to this ability, that explains this ability?To start with, despite my wearing a ruff, let me still state some working assumptions: I call \"mental objects\" - denoted, e.g., \\( m(\\text{giraffe})\\) etc. - whatever specific objects (\"the-cup-in-front-of-me\"), abstract concepts (\"love\"), and everything in between,  I may have on my mind. A mental object is not the same as the concept it pertains to, for example the mental object \"love\" and the concept \"love\" are different. But this distinction start to become important only once I ask about the nature of \"love\" and other concepts. I don't ask this question and distinguishing between them will introduce and unnecessary complication for my point. So \\( m(\\text{giraffe})\\) may just as well denote the concept \"giraffe\". Mental objects come with fuzzy boundaries but I assume that we can talk about them meaningfully and not necessarily always only as some \"phenomenological whole\". I assume that there exists a correspondence between mental objects and some physiological process - \\( p(\\text{giraffe})\\) - in my body, especially my brain, some sort of supervenience relation. And I assume, more for conceptual convenience than for necessity, that every specific mental phenomenon supervenes on a unique physiological state, i.e. one could hypothetically construct a function \\( f(\\cdot)\\) that maps every mental state to a unique physiological state (note that this is stronger than mere supervenience), i.e. \\( f(m(\\text{giraffe})) = p(\\text{giraffe})\\). Furthermore I assume that there exists some kind of mechanism - \\( mech(\\text{giraffe})\\) - by which the physiological states on which mental states supervene are implemented. This could be a complex pattern of or a rule for neural firing, something working in some regions or being distributed across many of them, a hormonal mechanism, I don't know and I don't need to care for this post. I just assume that it exists. Again, I also assume that the mechanism is uniquely determined for every physiological state, and thus, by the above assumption, by the mental object. A \"model\" is just the tuple \\( (mech(\\cdot),f(\\cdot),D)\\), where \\( D \\) is the domain of the model, i.e. set of all mental objects to which the model applies. So a model specifies a mechanism for some set of models, together with mappings between physiological states and mental objects. Finally, I say that I \"explain\" the occurrence of a mental phenomenon if I have a model that predicts the occurrence of the corresponding physiological state of affairs.I have a simple, quirky idea on the basis of which I want to develop such a model is then is that those models are good candidates for answering the above question of which the following is true: The mechanism that implements the physiological states for any mental object is independent of the level of abstraction of the concept that corresponds to this mental object. Call such models \"flat models\".What the heck is a flat model? Here is a little toy example: Take the mental objects \\( m(\\text{giraffe})\\) and \\( m(\\text{animal})\\). Now,\\( m(\\text{giraffe})\\) and \\( m(\\text{animal})\\) differ, I take it, to most people in their relative degree of abstractness, me included. Here, I think of the relative degree of abstractness of two mental concepts - denote it \\( a(m(\\text{giraffe}))\\) etc. - as being determined by whether one concept subsumes the other. So for most people, depending on their favourite ontology or metaphysics, conceive either of \\( m(\\text{giraffe})\\) as subsuming \\( m(\\text{animal})\\) - \"every giraffe is an animal but not every animal is a giraffe\" - or the other way around. Then, a flat model is just any model in which \\( mech(\\text{giraffe}) = mech(\\text{animal})\\), even if \\( a(c(\\text{giraffe})) \\neq a(c(\\text{animal}))\\), and the same for any other pair of mental objects. Specifically, what I have in mind here is that, whenever people think of some abstractum, they don't somehow think all the things that are subsumed by this abstractum at once but instead the thinking of the abstractum is implemented by exactly the same mechanism as the one that would be implemented if one was to think of any thing that is subsumed by this abstractum.How would flat models help to understand our ability to formulate self-referential statements? It does, I think, give a simple explanation for our ability to abstract from anything to anything, which itself is a key requirement for self-reference. For instance, in set theory, there exists the following principle:Unrestricted comprehension principle (UCP):\\( \\forall u (u \\in \\{ x | \\phi(x) \\} \\leftrightarrow \\phi(u))\\), for all formulae \\( \\phi(x)\\)This principle, which is also called \"unrestricted abstraction principle\", says that for any property (represented by the binary predicate \\( \\phi(\\cdot)\\), \"to have property \\( \\phi\\)\") there is the set of those entities that satisfy this property. This is, to me,  just a set-theoretic way of stating that I can formulate an abstract concept, a set, from any collection of entities. This is because, if you give me any entities \"\\( x\\)\" and \"\\( y\\)\", I can construct the property \"being either \\( x\\) or \\( y\\)\" and already, by the above principle, I have a new entity \"the set of \\( x\\) and \\( y\\)\" that can then figure in new sets, and so on. Importantly, one can prove that any set theory containing the UCP allows for paradoxical self-references (i.e. in those theories there exist sets that are members of themselves if and only they're not members of themselves).Now, flat models give, I think, quite a natural explanation for why the UCP would seem a natural feature of set theories. This is because their blindness for the relative degree of abstraction of concepts implies that any physiological limits to the ability to formulate new concepts, cannot, in such models, depend on how abstract the concepts from which one abstracts already are. Compare this, for example, with a non flat model in which the mechanism of thinking an abstractum would be modelled by a simultaneous implementation of the mechanism of all the objects that are subsumed by this abstractum. Such a model would involve an effectively exponential increase in the work that has to be done for thinking of an abstractum and one would not be surprised if this increase puts a bound on just how abstract one's abstracta can become, thus undermining the UCP.Another nice feature of flat models in this respect concerns the ability not only to produce self-referential statements, but moreover for these statements to be paradoxical: When I produced the set \"set containing \\( x\\) and \\( y\\)\" above, I tacitly assumed that we are free in constructing any property. Of course, if there was no such property as \"being either \\( x\\) or \\( y\\)\", then this would severely constrain the force of the UCP. It is only because I have a lot of freedom on the properties that I can construct those self-referential sets that are also paradoxical. Now, to answer the question which properties exist and which do not, I need a rule. This is a bit like, in a language, knowing the vocabulary is not enough. I also need grammatical rules to tell me which words I can combine, in what fashion. The second nice feature of flat models, then, is that their blindness for hierarchy gives this rule a very simple formulation: There exists a mechanism for every set of existing mechanisms. Non-flat hierarchies would, in general, have to specify the rule for different degrees of abstraction, which seems just unnecessarily complex.And that's basically it, that's the whole idea. To briefly sum up: If we model the physiology of abstraction using flat models, then we get particularly simple explanations for why the UCP seems to be a natural property of set theories and for the ability to formulate self-referential paradoxes (with a similar argument holding for semantic and epistemic self-reference). What to make of this? If we were interested in finding a good model for the physiology of abstraction, and if we think the argument above to be feasible, then this would lend some abductive support for flat models. But, for one, such support could only be very weak since there are many other non-flat models for which a similar argument could be made. For two, and more importantly, this is 2016, and introspection is not really the kind of thing we can use today for supporting physiological models, right?Maybe the argument could help us improve our understanding of paradoxes, or conceive of solutions to them? Well, the only thing that comes to my mind regarding this is the following: The ability to abstract must have been crucial for human-kind to develop, and so a neural architecture that makes abstraction very flexible and broadly available should correspondingly have been favourable. On the other hand, the ability to produce formal systems that do not suffer from inconsistency due to the possibility of self-referential paradoxes has, I take it, been relatively much less important (in fact I can't think of a single such formal system). So, from the physiological perspective of the brain, which itself of course does not know of any contradictions - to which the thought \"this thought does not happen\" is just like \"will they kick me out of this place if I don't order another coffee\" - asking for a solution to self-referential paradoxes seems not only non-sensical but even counter-productive! At the same time, there is no obvious argument known to me that our semantics or set theories would have to be sensitive to our models of the workings of the brain. In the end, formal languages that are both complete and consistent might be the core conceptual tool of the coming centuries. I doubt it, but anything goes...But then, what is all of this good for at all? Well, I find it striking that my limited knowledge of how neurons work and grow and inter-relate seems to go well together with how I experience my mental abilities (and this is certainly not by construction the case á la \"I use neurons to think about how neurons function and therefore are bound to arrive at models that go well together\"; I can indeed think of zillions of utterly incompatible ways for neurons to function, using the same neurons). And, in the end, ruffy musing like the above can still be helpful in formulating more rigorous research questions or challenges to existing evidence along the lines of: If your favourite model for abstraction is non-flat, then how do you explain the fact that I can run my abstraction sausage machine on any input you hand me? Let me know what you think.",
            "content_html": "<p>It's been a while. The reasons are the usual so let me not do go into lengthy explanations and apologies. I won't pursue the megalomanic project that I started the blog for, at least not for now. An essay on something related that I wrote on Kant's Mathematical Antinomies in Oxford, and a couple of conversations with clever people, showed me that my basic position concerning these things is even more problematic than I had foreseen (again, the usual...), so I'll pause that one to think a bit longer. For now, I have some other, more miscellaneous stuff lined up, and I'll start with a little quirky idea, nothing with much force, but, I find, interesting.</p><p>Let me put on my Cartesian ruff and do some armchair musing about the physiology of abstraction, that is, lets look at whether we can go say anything, by way of introspection, about what happens in the brain when we abstract (I know, it's 2016, I'm neither a philosopher of mind, nor a neuroscientist, this is just ridiculous...but then, from the little researching I did, there seems to exist no scientific theory on this at the moment and also it's a gloomy Sunday, so take it more as a form of hang over brain jogging...).</p><p><!--more--></p><p>Concretely, I want to think about the following: Start by noting that there are such things as paradoxes of self-reference, which means that people have an <i>ability</i> to formulate paradoxes of self-reference. The formulation of such paradoxes usually involves some form of abstraction (more below). This means that, if introspective observations of this kind have any relevance at all for the formulation of physiological models of abstraction (which I think, in principle they do, although I'm happy to admit that there are a zillion more pressing things to consider for the latter), then any such model would have to explain this ability of ours, ideally somewhat elegantly. Can we, then, playing the good ol' \"inference-to-the-best-explanation\"-game, develop a simple model of abstraction that naturally gives rise to this ability, that explains this ability?</p><p>To start with, despite my wearing a ruff, let me still state some working assumptions: I call \"mental objects\" - denoted, e.g., \\( m(\\text{giraffe})\\) etc. - whatever specific objects (\"the-cup-in-front-of-me\"), abstract concepts (\"love\"), and everything in between,  I may have on my mind. A mental object is not the same as the concept it pertains to, for example the <em>mental object </em>\"love\" and the <em>concept </em>\"love\" are different. But this distinction start to become important only once I ask about the nature of \"love\" and other concepts. I don't ask this question and distinguishing between them will introduce and unnecessary complication for my point. So \\( m(\\text{giraffe})\\) may just as well denote the concept \"giraffe\". Mental objects come with fuzzy boundaries but I assume that we can talk about them meaningfully and not necessarily always only as some \"phenomenological whole\". I assume that there exists a correspondence between mental objects and some physiological process - \\( p(\\text{giraffe})\\) - in my body, especially my brain, some sort of supervenience relation. And I assume, more for conceptual convenience than for necessity, that every specific mental phenomenon supervenes on a unique physiological state, i.e. one could hypothetically construct a function \\( f(\\cdot)\\) that maps every mental state to a unique physiological state (note that this is stronger than mere supervenience), i.e. \\( f(m(\\text{giraffe})) = p(\\text{giraffe})\\). Furthermore I assume that there exists some kind of mechanism - \\( mech(\\text{giraffe})\\) - by which the physiological states on which mental states supervene are implemented. This could be a complex pattern of or a rule for neural firing, something working in some regions or being distributed across many of them, a hormonal mechanism, I don't know and I don't need to care for this post. I just assume that it exists. Again, I also assume that the mechanism is uniquely determined for every physiological state, and thus, by the above assumption, by the mental object. A \"model\" is just the tuple \\( (mech(\\cdot),f(\\cdot),D)\\), where \\( D \\) is the domain of the model, i.e. set of all mental objects to which the model applies. So a model specifies a mechanism for some set of models, together with mappings between physiological states and mental objects. Finally, I say that I \"explain\" the occurrence of a mental phenomenon if I have a model that predicts the occurrence of the corresponding physiological state of affairs.</p><p>I have a simple, quirky idea on the basis of which I want to develop such a model is then is that those models are good candidates for answering the above question of which the following is true: The mechanism that implements the physiological states for any mental object is independent of the level of abstraction of the concept that corresponds to this mental object. Call such models \"flat models\".</p><p>What the heck is a flat model? Here is a little toy example: Take the mental objects \\( m(\\text{giraffe})\\) and \\( m(\\text{animal})\\). Now,\\( m(\\text{giraffe})\\) and \\( m(\\text{animal})\\) differ, I take it, to most people in their relative degree of abstractness, me included. Here, I think of the relative degree of abstractness of two mental concepts - denote it \\( a(m(\\text{giraffe}))\\) etc. - as being determined by whether one concept subsumes the other. So for most people, depending on their favourite ontology or metaphysics, conceive either of \\( m(\\text{giraffe})\\) as subsuming \\( m(\\text{animal})\\) - \"every giraffe is an animal but not every animal is a giraffe\" - or the other way around. Then, a flat model is just any model in which \\( mech(\\text{giraffe}) = mech(\\text{animal})\\), even if \\( a(c(\\text{giraffe})) \\neq a(c(\\text{animal}))\\), and the same for any other pair of mental objects. Specifically, what I have in mind here is that, whenever people think of some abstractum, they don't somehow think all the things that are subsumed by this abstractum at once but instead the thinking of the abstractum is implemented by exactly the same mechanism as the one that would be implemented if one was to think of any thing that is subsumed by this abstractum.</p><p>How would flat models help to understand our ability to formulate self-referential statements? It does, I think, give a simple explanation for our ability to abstract from anything to anything, which itself is a key requirement for self-reference. For instance, in set theory, there exists the following principle:</p><p style=\"text-align:left;padding-left:30px;\"><strong>Unrestricted comprehension principle (UCP):</strong></p><p style=\"padding-left:30px;\">\\( \\forall u (u \\in \\{ x | \\phi(x) \\} \\leftrightarrow \\phi(u))\\), for all formulae \\( \\phi(x)\\)</p><p>This principle, which is also called \"unrestricted abstraction principle\", says that for any property (represented by the binary predicate \\( \\phi(\\cdot)\\), \"to have property \\( \\phi\\)\") there is the set of those entities that satisfy this property. This is, to me,  just a set-theoretic way of stating that I can formulate an abstract concept, a set, from any collection of entities. This is because, if you give me any entities \"\\( x\\)\" and \"\\( y\\)\", I can construct the property \"being either \\( x\\) or \\( y\\)\" and already, by the above principle, I have a new entity \"the set of \\( x\\) and \\( y\\)\" that can then figure in new sets, and so on. Importantly, one can prove that any set theory containing the UCP allows for paradoxical self-references (i.e. in those theories there exist sets that are members of themselves if and only they're not members of themselves).</p><p>Now, flat models give, I think, quite a natural explanation for why the UCP would seem a natural feature of set theories. This is because their blindness for the relative degree of abstraction of concepts implies that any physiological limits to the ability to formulate new concepts, cannot, in such models, depend on how abstract the concepts from which one abstracts already are. Compare this, for example, with a non flat model in which the mechanism of thinking an abstractum would be modelled by a simultaneous implementation of the mechanism of all the objects that are subsumed by this abstractum. Such a model would involve an effectively exponential increase in the work that has to be done for thinking of an abstractum and one would not be surprised if this increase puts a bound on just how abstract one's abstracta can become, thus undermining the UCP.</p><p>Another nice feature of flat models in this respect concerns the ability not only to produce self-referential statements, but moreover for these statements to be paradoxical: When I produced the set \"set containing \\( x\\) and \\( y\\)\" above, I tacitly assumed that we are free in constructing any property. Of course, if there was no such property as \"being either \\( x\\) or \\( y\\)\", then this would severely constrain the force of the UCP. It is only because I have a lot of freedom on the properties that I can construct those self-referential sets that are also paradoxical. Now, to answer the question which properties exist and which do not, I need a rule. This is a bit like, in a language, knowing the vocabulary is not enough. I also need grammatical rules to tell me which words I can combine, in what fashion. The second nice feature of flat models, then, is that their blindness for hierarchy gives this rule a very simple formulation: There exists a mechanism for every set of existing mechanisms. Non-flat hierarchies would, in general, have to specify the rule for different degrees of abstraction, which seems just unnecessarily complex.</p><p>And that's basically it, that's the whole idea. To briefly sum up: If we model the physiology of abstraction using flat models, then we get particularly simple explanations for why the UCP seems to be a natural property of set theories and for the ability to formulate self-referential paradoxes (with a similar argument holding for semantic and epistemic self-reference). What to make of this? If we were interested in finding a good model for the physiology of abstraction, and if we think the argument above to be feasible, then this would lend some abductive support for flat models. But, for one, such support could only be very weak since there are many other non-flat models for which a similar argument could be made. For two, and more importantly, this is 2016, and introspection is not really the kind of thing we can use today for supporting physiological models, right?</p><p>Maybe the argument could help us improve our understanding of paradoxes, or conceive of solutions to them? Well, the only thing that comes to my mind regarding this is the following: The ability to abstract must have been crucial for human-kind to develop, and so a neural architecture that makes abstraction very flexible and broadly available should correspondingly have been favourable. On the other hand, the ability to produce formal systems that do not suffer from inconsistency due to the possibility of self-referential paradoxes has, I take it, been relatively much less important (in fact I can't think of a single such formal system). So, from the physiological perspective of the brain, which itself of course does not know of any contradictions - to which the thought \"this thought does not happen\" is just like \"will they kick me out of this place if I don't order another coffee\" - asking for a solution to self-referential paradoxes seems not only non-sensical but even counter-productive! At the same time, there is no obvious argument known to me that our semantics or set theories would have to be sensitive to our models of the workings of the brain. In the end, formal languages that are both complete and consistent might be the core conceptual tool of the coming centuries. I doubt it, but anything goes...</p><p>But then, what is all of this good for at all? Well, I find it striking that my limited knowledge of how neurons work and grow and inter-relate seems to go well together with how I experience my mental abilities (and this is certainly not by construction the case á la \"I use neurons to think about how neurons function and therefore are bound to arrive at models that go well together\"; I can indeed think of zillions of utterly incompatible ways for neurons to function, using the same neurons). And, in the end, ruffy musing like the above can still be helpful in formulating more rigorous research questions or challenges to existing evidence along the lines of: If your favourite model for abstraction is non-flat, then how do you explain the fact that I can run my abstraction sausage machine on any input you hand me? Let me know what you think.</p>",
            "url": "http://localhost:4000/2016/04/28/280/",
            
            
            
            
            
            "date_published": "2016-04-28T07:38:58+00:00",
            "date_modified": "2016-04-28T07:38:58+00:00",
            
                "author": "{"login"=>"pboes", "email"=>"paul.boes.10@ucl.ac.uk", "display_name"=>"pboes", "first_name"=>"", "last_name"=>""}"
            
        },
    
        {
            "id": "http://localhost:4000/2013/10/30/writing-a-blog-take-one/",
            "title": "A transcendental interpretation of Quantum Mechanics?",
            "summary": null,
            "content_text": "Here we are with the second entry. I've been through some tough times with it, producing some ten thousand words of crap and changing topic several times on the go. Obvious problem: Being too ambitious, easy solution: Being less ambitious. So I guess I will chop up the message for this final topic in easy bits and post them as I go. This also makes sense in terms of getting feedback while producing the follow-up posts.Today's menu: First of all, give you a glimpse of the larger idea about to be presented in the next couple of posts, and then serve the first chunk.The first big sign post aim will be to propose the possibility of a consistent and adequate transcendental interpretation of the laws of quantum mechanics, where the term transcendental will mean something quite different from the Kantian sense, being close enough to the latter, however, to avoid some stupid neologism.  This possibility will be supported a fortiori, meaning that I will argue more generally for the feasibility of a transcendental interpretation of laws or principles, with the laws of QM then being only a specific case to which the general argument applies in a specific costume.So here is a sketch of this more general argument:1. The mental process of abstraction is a creative process in the sense that its result, the abstraction, lets us talk and think about the world in formerly unavailable terms.Abstractions carry physical import.Physical import and creative aspects of abstraction can lead to situations in which physical non-sense can be described physically.The incompatibility between some abstractive processes can be captured in laws or principles, both of which for me are nothing but constraints with certain realm of validity. This can easiest be seen in information theory.1.-3. can be turned into a transcendental argument, consequently 4. can be taken to be a transcendental interpretation of laws.How exactly 1.-5. are then applied to the specific laws of quantum mechanics, need not concern us just now. There are more than enough problems in this first argument.  This first entry will cover 1. - 3.1. The mental process of abstraction is a creative process in the sense that its result, the abstraction, lets us talk and think about the world in formerly unavailable terms.In the sense I mean the above, it may even be a bit trivial: By definition, the result of an abstractive process is an abstraction, no? And this abstraction stands in a certain relation to what the specific things that it can be applied to, the set of which let me call an abstraction's \"applicability set\". If that was not the case, how should the abstraction have been abstracted from at least a subset of the latter in the first place? Consequently, we can use abstractions to talk about and describe their applicability sets. But using an abstraction to talk about whatever that abstraction applies to couldn't have been carried out unless that abstraction wasn't there. The notion of an applicability set without corresponding abstraction makes no sense. And that's all I want to say here.For example, we take physical objects in different relative positions and then we abstract geometrical properties from these: Look, if we put these balls next to each other then they make a \"line\". Now, only after we've developed the concept of a \"line\" can every ball, i.e. every element of the applicability set of the abstraction \"line\"  have the property of \"lying on a line\". So all of a sudden things in the world can be aligned! And here comes a key point: In a sense, a sense which is carefully to be specified below, this possibility dramatically increases the ways for the world to be like.2. Abstractions carry physical import.This is a more substantial point than the first. What it says is that we can treat abstractions, unlike what their name suggests, as somehow \"physical\", i.e. \"out-there-worldly\", objects in our thought, which is to say that they are subject to constraints in our mind analogous to the way that physical objects are constrained by laws of nature in the physical world (Actually, looking at the broader argument I want to make this is a bad formulation, something like \"there exists a strong link between what we call \"laws of nature\" and the actions we can carry out with abstractions\" would be better but that would be unnecessarily confusing for the point I want to make right now). One might go as far as to argue that this physical import is actually necessary to make any relation of an abstraction to its applicability set possible in the first place, but that's not really necessary for my argument. All I need for now is that this physical import exists at least for certain kinds of abstractions.Now to motivate this I think I need to support two independent points:  That there are constraints to what one can do with abstractions at all and that these constraints are to do with the physical laws of nature.Let me give some examples for the first: In fact, I wrote quite a long essay on the \"material-ladenness\" of the \"point\" concept, i.e. the fact that the mathematical concept of a point is subject to constraints on what one can do with it, where these constraints derive from the physical objects from which the point concept had been abstracted, and how this material-ladenness influenced Einstein's critique of quantum mechanics. It's linked HERE if you're interested. The key point there was that the points of a manifold upon which the field is defined are independent from another by virtue of not being the same point and that this independence condition, which is not an a priori datum, reflects a constraint on the properties of the point concept, at least when used to construct a physical argument.What about the second point: Why should the way in which our abstractions are constrained have anything to do with the laws of physics? Again, there exists very interesting work on this question along the lines of what I try to sketch here, for example by Peter Damerow at the Max Planck Institute for the History of Science. The short and imprecise answer is: Because the physical world is the one from which all our abstractions stem in the first place. So in the above example it's the combination of the impenetrability of matter that we perceive all around us and the impression of object permanence.3. Physical import and creative aspects of abstraction can lead to situations in which physical non-sense can be described physically.So far, so good. Now it is by putting these two points together that things start to become really interesting: As a consequence of 1. and 2., I think, it is possible that abstractions, or the connection of several ones, can enable us to describe physical scenarios that lie outside the realm of what is physically meaningful. You might think that at least the consequence statement (independent of whether it actually follows from 1. and 2.) is true and I shouldn't make a fuzz: \"A world in which everything gravitates upwards\", \"A world in which birds fly backwards\". But I mean physical meaningfulness, not physical possibility. What I'm really after are scenarios in which the physical and the conceptual blur: The spatial or temporal end of the universe, the vacuum, etc. I think that the only reason we ever take these scenarios seriously is because of the truth of 1. and 2. lead to such a blur in the first place. And, I believe further, that the recognition of this being the reason for our taking these scenarios seriously, should lead us to stop taking them seriously, although that last point will be motivated separately.But one after the other: How does 3. follow from 1. and 2.? It certainly doesn't in any strict logical sense, all points are way too vague for this, although I try to make the as precise as I can. The way I see it is this: As we've seen abstractions allow to describe the scenarios in which their applicability sets figure new ways, similar to the way of choosing a different coordinate system for a system. But since abstraction is not a clear-cut process (whatever it is, it isn't clear-cut), when bringing together several abstractions, as is required for any non-trivial scenario, we can phrase sentences/thoughts, that lie outside the intersection of the several applicability sets involved. Now, were abstractions completely unphysical, this wouldn't result in any problems, but given that they are (that's what point 2. says), these descriptions seem to describe a scenario that could actually happen. And this is exactly the blur I'm on about.Examples! The question of a line of balls at the end of the universe is such a thing: We somehow come up with the concept of an infinite line and then it clashes with the concept of an end. And it would be completely fine for someone to say \"well, in one abstract description the line of balls if infinite, in the other the universe is finite, but that's not really problematic because all these things are just abstract concepts\" if not things like \"universe\", \"balls\", and even \"lines\" carried physical import. So really the problem arises from believing both the above descriptions to be physical and therefore requiring their physical consistency.Or take another one:  We put some stuff in a room, and more, and more, and then we abstract the possibility of it being able to be completely full, or completely empty, even though we've never actually reached that state ourselves, it simply seems to be the natural consequence of keeping to put stuff into the room, no? But here again, the concept of complete emptiness or filledness allows us to talk about a state of that room that seems physically sensible, although this being a physically meaningful scenario is in no way supported (even though admittedly not falsified either) by what we ever did in the room.Unsurprisingly, this form of abstraction, in which we arrive at an abstract concept by thinking a physical process \"to it logical end\" is a very common source of headache, but we're not yet at the stage of judging this problematic or not.Now, I guess at the beginning of the next entry I discuss some more examples of this, but I better make a stop here, and just get this stuff online for a change. I hope that it made some sense and you see how the third point builds on the first two. Please comment your ideas, worries, blabla…",
            "content_html": "<p>Here we are with the second entry. I've been through some tough times with it, producing some ten thousand words of crap and changing topic several times on the go. Obvious problem: Being too ambitious, easy solution: Being less ambitious. So I guess I will chop up the message for this final topic in easy bits and post them as I go. This also makes sense in terms of getting feedback while producing the follow-up posts.<br />Today's menu: First of all, give you a glimpse of the larger idea about to be presented in the next couple of posts, and then serve the first chunk.</p><p><!--more--><br />The first big sign post aim will be to propose the possibility of a consistent and adequate transcendental interpretation of the laws of quantum mechanics, where the term transcendental will mean something quite different from the Kantian sense, being close enough to the latter, however, to avoid some stupid neologism.  This possibility will be supported a fortiori, meaning that I will argue more generally for the feasibility of a transcendental interpretation of laws or principles, with the laws of QM then being only a specific case to which the general argument applies in a specific costume.<br />So here is a sketch of this more general argument:</p><ol><li>1. The mental process of abstraction is a creative process in the sense that its result, the abstraction, lets us talk and think about the world in formerly unavailable terms.</li><li>Abstractions carry physical import.</li><li>Physical import and creative aspects of abstraction can lead to situations in which physical non-sense can be described physically.</li><li>The incompatibility between some abstractive processes can be captured in laws or principles, both of which for me are nothing but constraints with certain realm of validity. This can easiest be seen in information theory.</li><li>1.-3. can be turned into a transcendental argument, consequently 4. can be taken to be a transcendental interpretation of laws.</li></ol><p>How exactly 1.-5. are then applied to the specific laws of quantum mechanics, need not concern us just now. There are more than enough problems in this first argument.  This first entry will cover 1. - 3.</p><p><strong>1. The mental process of abstraction is a creative process in the sense that its result, the abstraction, lets us talk and think about the world in formerly unavailable terms.</strong><br />In the sense I mean the above, it may even be a bit trivial: By definition, the result of an abstractive process is an abstraction, no? And this abstraction stands in a certain relation to what the specific things that it can be applied to, the set of which let me call an abstraction's \"applicability set\". If that was not the case, how should the abstraction have been abstracted from at least a subset of the latter in the first place? Consequently, we can use abstractions to talk about and describe their applicability sets. But using an abstraction to talk about whatever that abstraction applies to couldn't have been carried out unless that abstraction wasn't there. The notion of an applicability set without corresponding abstraction makes no sense. And that's all I want to say here.<br />For example, we take physical objects in different relative positions and then we abstract geometrical properties from these: Look, if we put these balls next to each other then they make a \"line\". Now, only after we've developed the concept of a \"line\" can every ball, i.e. every element of the applicability set of the abstraction \"line\"  have the property of \"lying on a line\". So all of a sudden things in the world can be aligned! And here comes a key point: In a sense, a sense which is carefully to be specified below, this possibility dramatically increases the ways for the world to be like.</p><p><strong>2. Abstractions carry physical import.</strong><br />This is a more substantial point than the first. What it says is that we can treat abstractions, unlike what their name suggests, as somehow \"physical\", i.e. \"out-there-worldly\", objects in our thought, which is to say that they are subject to constraints in our mind analogous to the way that physical objects are constrained by laws of nature in the physical world (Actually, looking at the broader argument I want to make this is a bad formulation, something like \"there exists a strong link between what we call \"laws of nature\" and the actions we can carry out with abstractions\" would be better but that would be unnecessarily confusing for the point I want to make right now). One might go as far as to argue that this physical import is actually necessary to make any relation of an abstraction to its applicability set possible in the first place, but that's not really necessary for my argument. All I need for now is that this physical import exists at least for certain kinds of abstractions.<br />Now to motivate this I think I need to support two independent points:  That there are constraints to what one can do with abstractions at all and that these constraints are to do with the physical laws of nature.<br />Let me give some examples for the first: In fact, I wrote quite a long essay on the \"material-ladenness\" of the \"point\" concept, i.e. the fact that the mathematical concept of a point is subject to constraints on what one can do with it, where these constraints derive from the physical objects from which the point concept had been abstracted, and how this material-ladenness influenced Einstein's critique of quantum mechanics. It's linked <a href=\"http://beingbutlumps.files.wordpress.com/2013/10/hpsc3007-conditions-for-the-ontic-treatment-of-mathematics-zcqsg05-revised.pdf\">HERE</a> if you're interested. The key point there was that the points of a manifold upon which the field is defined are independent from another by virtue of not being the same point and that this independence condition, which is not an a priori datum, reflects a constraint on the properties of the point concept, at least when used to construct a physical argument.<br />What about the second point: Why should the way in which our abstractions are constrained have anything to do with the laws of physics? Again, there exists very interesting work on this question along the lines of what I try to sketch here, for example by Peter Damerow at the Max Planck Institute for the History of Science. The short and imprecise answer is: Because the physical world is the one from which all our abstractions stem in the first place. So in the above example it's the combination of the impenetrability of matter that we perceive all around us and the impression of object permanence.</p><p><strong>3. Physical import and creative aspects of abstraction can lead to situations in which physical non-sense can be described physically.</strong><br />So far, so good. Now it is by putting these two points together that things start to become really interesting: As a consequence of 1. and 2., I think, it is possible that abstractions, or the connection of several ones, can enable us to describe physical scenarios that lie outside the realm of what is physically meaningful. You might think that at least the consequence statement (independent of whether it actually follows from 1. and 2.) is true and I shouldn't make a fuzz: \"A world in which everything gravitates upwards\", \"A world in which birds fly backwards\". But I mean physical meaningfulness, not physical possibility. What I'm really after are scenarios in which the physical and the conceptual blur: The spatial or temporal end of the universe, the vacuum, etc. I think that the only reason we ever take these scenarios seriously is because of the truth of 1. and 2. lead to such a blur in the first place. And, I believe further, that the recognition of this being the reason for our taking these scenarios seriously, should lead us to stop taking them seriously, although that last point will be motivated separately.<br />But one after the other: How does 3. follow from 1. and 2.? It certainly doesn't in any strict logical sense, all points are way too vague for this, although I try to make the as precise as I can. The way I see it is this: As we've seen abstractions allow to describe the scenarios in which their applicability sets figure new ways, similar to the way of choosing a different coordinate system for a system. But since abstraction is not a clear-cut process (whatever it is, it isn't clear-cut), when bringing together several abstractions, as is required for any non-trivial scenario, we can phrase sentences/thoughts, that lie outside the intersection of the several applicability sets involved. Now, were abstractions completely unphysical, this wouldn't result in any problems, but given that they are (that's what point 2. says), these descriptions seem to describe a scenario that could actually happen. And this is exactly the blur I'm on about.<br />Examples! The question of a line of balls at the end of the universe is such a thing: We somehow come up with the concept of an infinite line and then it clashes with the concept of an end. And it would be completely fine for someone to say \"well, in one abstract description the line of balls if infinite, in the other the universe is finite, but that's not really problematic because all these things are just abstract concepts\" if not things like \"universe\", \"balls\", and even \"lines\" carried physical import. So really the problem arises from believing both the above descriptions to be physical and therefore requiring their physical consistency.<br />Or take another one:  We put some stuff in a room, and more, and more, and then we abstract the possibility of it being able to be completely full, or completely empty, even though we've never actually reached that state ourselves, it simply seems to be the natural consequence of keeping to put stuff into the room, no? But here again, the concept of complete emptiness or filledness allows us to talk about a state of that room that seems physically sensible, although this being a physically meaningful scenario is in no way supported (even though admittedly not falsified either) by what we ever did in the room.<br />Unsurprisingly, this form of abstraction, in which we arrive at an abstract concept by thinking a physical process \"to it logical end\" is a very common source of headache, but we're not yet at the stage of judging this problematic or not.<br />Now, I guess at the beginning of the next entry I discuss some more examples of this, but I better make a stop here, and just get this stuff online for a change. I hope that it made some sense and you see how the third point builds on the first two. Please comment your ideas, worries, blabla…</p>",
            "url": "http://localhost:4000/2013/10/30/writing-a-blog-take-one/",
            
            
            
            
            
            "date_published": "2013-10-30T15:29:09+00:00",
            "date_modified": "2013-10-30T15:29:09+00:00",
            
                "author": "{"login"=>"pboes", "email"=>"paul.boes.10@ucl.ac.uk", "display_name"=>"pboes", "first_name"=>"", "last_name"=>""}"
            
        },
    
        {
            "id": "http://localhost:4000/2013/02/06/why-this-blog/",
            "title": "why this blog",
            "summary": null,
            "content_text": "I hold a number of beliefs about the world that seem inconsistent and these beliefs do not concern the world of my everyday life, where concepts and principles are (and should be) vague, things are in a constant state of tension and the term “inconsistency” is just as vaguely applicable. Instead, the beliefs I mean are those that lie at the conceptual and interpretative basis of our physical theories about the world, especially at the microscopic level. Here the possibility for inconsistency, logically defined as the impossibility of two propositions to be true at the same time, of two beliefs (or their statement) becomes more clear-cut as the beliefs grow sharper.It is the simple purpose of this blog to get clearer about a number of these latter beliefs and see in what form, and if at all, they can sustain another or simply co-exist independently. To give the whole thing at least somewhat of a red thread (which it is doomed to lose, I know myself well enough to predict this), let me say that what I want to concentrate on in the following is this  question: How can we talk *(without being naively realist) about the way, in which *systems are ontologically constituted by their mutual interactions?As may be indicated by the words in italics, some of the major topics and people in this blog will be: Meaningful demarcation of “systems” (in epistemology, semantics and ontology) and “intersystematic relationships”, Wittgenstein; actuality, potentiality and phenomenology (Heidegger, Sartre); Information theory and complexity; self-reference and -sustainance, the “global” and “local” applicability of concepts and ways of coping with regresses a la Zenon, reductionism and emergentism; holism.Finally, there are two obvious reasons for me to present these texts in public: Firstly, I can use my vanity to make sure that I write the texts with the reader in mind (who himself will, naturally, take all his criticisms about the text as a further confirmation of the quite tremendous stupidity of their author) and consequently be careful with my formulation of things and their (the texts’) readability. Secondly, I hope to get feedback by people. That’s what blogs are there for (beyond exhibitionism), no?To start off, it seems best to play with open cards and simply enumerate some of the beliefs I currently hold, for whatever reason, and see how I would formulate them at this early moment, to give you a feeling of what I am talking about:  It is a natural but “harmful” consequence of our mechanisms of abstraction in language that the results are “over-ambitiously  abstracted”, in the sense that, for example, the dichotomies that result from abstractions suggest possible ways  for the world to be like by spanning a field between extremes, where this field in fact is much larger than what is actually case. I heard a nice way of paraphrasing this, at least that’s what I made of it, in a recent lecture on buddhist philosophy: “Atomism is both necessary and false…” (I should at this point note that I am not a rainbow quantum guy, I am certainly not). Another, different way of formulating a similar idea I have read years ago is in Adorno, where he asks why, by the act of subsuming a number of elements under a category, this category, by this very act, was somehow promoted from the objects it contains.  There is, at least on the level of microscopic physics, nothing but actuality, by which I mean that things can only “be” but not “possibly be”. Whether or not things can “not be”, I have not decided. This implies that counterfactual reasoning on microphysical entities cannot be meaningfully employed just as little as talk about possible worlds.3.  The world is holistic, by which I only mean that the whole contains more than the sum of its parts. Still, we cannot know what we mean when we talk about the “whole”. I am also very much convinced that we can formulate holism better than in the above way.3.1 The world, as a whole, is somehow self-sustaining. This is important for top-down questions of “the whole”. For a self-sustaining universe the concept of “outside the universe” is meaningless and criticism cannot arise. The self-sustainance is particularly important here in that sustainance implies a being held together of the universe by itself.3.2. The question how a “cut” or “caesura” is required to acquire meaning, is very important, particularly with respect to the possible loci of this cut: Is it to be found only in language or can we place it into the ontological realm?  I believe that the phenomenological concepts of intentionality and transcendence are very, very important and under-rated in physics: A system is nothing but the totality of its effects on its environment, its being-in-the-world (I try to make of Sartre’s stuff the last thing he would have wanted anybody to do, I completely ignore and misunderstand his point…everything goes)  I believe in the following reading of Humean supervenience: The world consists of (actual) particulars the (monadic?) properties of which induce dynamics (not necessarily deterministic) that allow for the formulation of laws as generally true (and instantiated) facts, without however, imposing an element of necessity to these laws that is not equivalently present in the properties. In other words: In any way, in which the question about the primacy of the particularly true as opposed to the universally true is not trivialised by the logical equivalence of the two possibilities, the particularly true is primary.  Any way of splitting the world into parts involves a saturation of the information that can be stored in /extracted from this part, at least for a fixed context.  The existence of “configurational” (as opposed to either logical or spatio-temporal) neighbourhoods induces locality constraints on the propagation of information/effects, as partly captured by field theories.  Stable structures are perceived because they result from a constructive interference between the perceiving and the perceived system. Thus, while all modes of “oscillation” in the interaction are allowed, only the constructive ones do not suffer decay.          8.1 This last point is an example for the fruitful application of eliminative arguments: Rather than saying only what (and nothing else) is possible, we should focus on no-go-arguments that say only what *is *not possible (but everything else is).  Non-linear, chaotic, “spontaneous” events are key to understanding the re-establishment of dynamics in a universe that otherwise would tend towards stasis through global symmetry.Now these are only some of those beliefs I am worried about, but I can imagine that only from skimming through them a lot of tensions become apparent. All of these points require further motivation and explication and, if everything goes according to plan, they will. So let’s see what this turns into.",
            "content_html": "<p>I hold a number of beliefs about the world that seem inconsistent and these beliefs do not concern the world of my everyday life, where concepts and principles are (and should be) vague, things are in a constant state of tension and the term “inconsistency” is just as vaguely applicable. Instead, the beliefs I mean are those that lie at the conceptual and interpretative basis of our physical theories about the world, especially at the microscopic level. Here the possibility for inconsistency, logically defined as the impossibility of two propositions to be true at the same time, of two beliefs (or their statement) becomes more clear-cut as the beliefs grow sharper.</p><p>It is the simple purpose of this blog to get clearer about a number of these latter beliefs and see in what form, and if at all, they can sustain another or simply co-exist independently. To give the whole thing at least somewhat of a red thread (which it is doomed to lose, I know myself well enough to predict this), let me say that what I want to concentrate on in the following is this  question: How can we <em>talk *(without being naively realist) about the way, in which *systems</em> are <em>ontologically</em> <em>constituted</em> by their <em>mutual interactions</em>?As may be indicated by the words in italics, some of the major topics and people in this blog will be: Meaningful demarcation of “systems” (in epistemology, semantics and ontology) and “intersystematic relationships”, Wittgenstein; actuality, potentiality and phenomenology (Heidegger, Sartre); Information theory and complexity; self-reference and -sustainance, the “global” and “local” applicability of concepts and ways of coping with regresses a la Zenon, reductionism and emergentism; holism.</p><p>Finally, there are two obvious reasons for me to present these texts in public: Firstly, I can use my vanity to make sure that I write the texts with the reader in mind (who himself will, naturally, take all his criticisms about the text as a further confirmation of the quite tremendous stupidity of their author) and consequently be careful with my formulation of things and their (the texts’) readability. Secondly, I hope to get feedback by people. That’s what blogs are there for (beyond exhibitionism), no?</p><p>To start off, it seems best to play with open cards and simply enumerate some of the beliefs I currently hold, for whatever reason, and see how I would formulate them at this early moment, to give you a feeling of what I am talking about:</p><ol>  <li>It is a natural but “harmful” consequence of our mechanisms of abstraction in language that the results are “over-ambitiously  abstracted”, in the sense that, for example, the dichotomies that result from abstractions suggest possible ways  for the world to be like by spanning a field between extremes, where this field in fact is much larger than what is actually case. I heard a nice way of paraphrasing this, at least that’s what I made of it, in a recent lecture on buddhist philosophy: “Atomism is both necessary and false…” (I should at this point note that I am not a rainbow quantum guy, I am certainly not). Another, different way of formulating a similar idea I have read years ago is in Adorno, where he asks why, by the act of subsuming a number of elements under a category, this category, by this very act, was somehow promoted from the objects it contains.</li>  <li>There is, at least on the level of microscopic physics, nothing but actuality, by which I mean that things can only “be” but not “possibly be”. Whether or not things can “not be”, I have not decided. This implies that counterfactual reasoning on microphysical entities cannot be meaningfully employed just as little as talk about possible worlds.3.  The world is holistic, by which I only mean that the whole contains more than the sum of its parts. Still, we cannot know what we mean when we talk about the “whole”. I am also very much convinced that we can formulate holism better than in the above way.3.1 The world, as a whole, is somehow self-sustaining. This is important for top-down questions of “the whole”. For a self-sustaining universe the concept of “outside the universe” is meaningless and criticism cannot arise. The self-sustainance is particularly important here in that sustainance implies a being held together of the universe by itself.3.2. The question how a “cut” or “caesura” is required to acquire meaning, is very important, particularly with respect to the possible loci of this cut: Is it to be found only in language or can we place it into the ontological realm?</li>  <li>I believe that the phenomenological concepts of intentionality and transcendence are very, very important and under-rated in physics: A system is nothing but the totality of its effects on its environment, its being-in-the-world (I try to make of Sartre’s stuff the last thing he would have wanted anybody to do, I completely ignore and misunderstand his point…everything goes)</li>  <li>I believe in the following reading of Humean supervenience: The world consists of (actual) particulars the (monadic?) properties of which induce dynamics (not necessarily deterministic) that allow for the formulation of laws as generally true (and instantiated) facts, without however, imposing an element of necessity to these laws that is not equivalently present in the properties. In other words: In any way, in which the question about the primacy of the particularly true as opposed to the universally true is not trivialised by the logical equivalence of the two possibilities, the particularly true is primary.</li>  <li>Any way of splitting the world into parts involves a saturation of the information that can be stored in /extracted from this part, at least for a fixed context.</li>  <li>The existence of “configurational” (as opposed to either logical or spatio-temporal) neighbourhoods induces locality constraints on the propagation of information/effects, as partly captured by field theories.</li>  <li>Stable structures are perceived because they result from a constructive interference between the perceiving and the perceived system. Thus, while all modes of “oscillation” in the interaction are allowed, only the constructive ones do not suffer decay.          8.1 This last point is an example for the fruitful application of eliminative arguments: Rather than saying <em>only what</em> (and nothing else) is possible, we should focus on no-go-arguments that say <em>only what *is *not</em> possible (but everything else is).</li>  <li>Non-linear, chaotic, “spontaneous” events are key to understanding the re-establishment of dynamics in a universe that otherwise would tend towards stasis through global symmetry.Now these are only some of those beliefs I am worried about, but I can imagine that only from skimming through them a lot of tensions become apparent. All of these points require further motivation and explication and, if everything goes according to plan, they will. So let’s see what this turns into.</li></ol>",
            "url": "http://localhost:4000/2013/02/06/why-this-blog/",
            
            
            
            
            
            "date_published": "2013-02-06T21:21:50+00:00",
            "date_modified": "2013-02-06T21:21:50+00:00",
            
                "author": "{"login"=>"pboes", "email"=>"paul.boes.10@ucl.ac.uk", "display_name"=>"pboes", "first_name"=>"", "last_name"=>""}"
            
        }
    
    ]
}